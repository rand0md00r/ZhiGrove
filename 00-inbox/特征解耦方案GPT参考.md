å¥½çš„ï¼ä¸‹é¢ç»™å‡º**4 å¥—â€œå¯ç›´æ¥è½åœ° + æœ‰è®ºæ–‡èƒŒä¹¦â€çš„æ¨¡æ€è§£è€¦æ–¹æ¡ˆ**ã€‚æ¯å¥—éƒ½åŒ…å«ï¼šæ€è·¯â†’æœ€å°ä¼ªä»£ç â†’è®­ç»ƒè¦ç‚¹ä¸å¯¹åº”å‚è€ƒæ–‡çŒ®ã€‚ä½ å¯ä»¥æŠŠä»»æ„ä¸€å¥—å†™è¿›ç®€å†â€œéš¾ç‚¹&æ–¹æ¡ˆâ€ï¼Œå¹¶åœ¨è®ºæ–‡èŠ‚é€‰é‡Œç»™å‡ºå‡ºå¤„ã€‚

---

# æ–¹æ¡ˆä¸€ï½œæŒ‰æ¨¡æ€çš„æŸ¥è¯¢åº“ï¼ˆQ-Former/Perceiver é£æ ¼ï¼‰

**è¦ç‚¹**ï¼šç»™æ¯ä¸ªæ¨¡æ€è®¾ç‹¬ç«‹çš„æŸ¥è¯¢å‘é‡åº“ï¼ˆQ\_textã€Q\_imgï¼‰ï¼Œåªå¯¹å„è‡ªæ¨¡æ€åš cross-attn æŠ½å–ï¼›å†ç”¨ä¸€ä¸ªå°‘é‡çš„å…±äº«æŸ¥è¯¢ Q\_share èšåˆå¤šæ¨¡æ€å…¬å…±ä¿¡æ¯ã€‚
**å‡ºå¤„**ï¼šBLIP-2 çš„ **Q-Former** ç”¨å¯å­¦ä¹  queries è¿æ¥è§†è§‰ç¼–ç å™¨ä¸ LLMï¼›Flamingo çš„ **Perceiver-Resampler**/Perceiver-IO ç”¨â€œæ½œåœ¨æŸ¥è¯¢â€è·¨æ¨¡æ€è¯»å–ç‰¹å¾ã€‚([arXiv][1], [NeurIPS ä¼šè®®è®°å½•][2])

**æœ€å°ä¼ªä»£ç ï¼ˆPyTorch é£æ ¼ï¼‰**

```python
class DualBankExtractor(nn.Module):
    def __init__(self, d, n_q_text=8, n_q_img=8, n_q_share=4):
        super().__init__()
        self.Q_text  = nn.Parameter(torch.randn(n_q_text, d))
        self.Q_img   = nn.Parameter(torch.randn(n_q_img,  d))
        self.Q_share = nn.Parameter(torch.randn(n_q_share, d))
        self.cross   = MultiheadAttention(d, num_heads=8, batch_first=True)

    def xattn(self, Q, KV):
        B = KV.size(0)
        Q = Q.unsqueeze(0).expand(B, -1, -1)
        Z, A = self.cross(Q, KV, KV, need_weights=True)  # (B,Lq,D), (B,Lq,Lkv)
        return Z, A

    def forward(self, txt_tokens, img_tokens, open_share=False):
        Zt, At = self.xattn(self.Q_text,  txt_tokens)     # ç§æœ‰ï¼šåªè¯»æ–‡æœ¬
        Zi, Ai = self.xattn(self.Q_img,   img_tokens)     # ç§æœ‰ï¼šåªè¯»å›¾åƒ
        Zs, As = (None, None)
        if open_share:
            KV = torch.cat([txt_tokens, img_tokens], dim=1)
            Zs, As = self.xattn(self.Q_share, KV)         # å…±äº«æ¡¥ï¼šè¯»ä¸¤æ¨¡æ€
        return Zt, Zi, Zs, {"At": At, "Ai": Ai, "As": As}
```

**è®­ç»ƒè¦ç‚¹ï¼ˆé…å¥—æŸå¤±ï¼‰**

* å…ˆ**å†»ç»“å…±äº«æ¡¥**ï¼ˆåªè®­ç§æœ‰åˆ†æ”¯ 30% è¿›åº¦ï¼‰ï¼Œå†çº¿æ€§æ”¾å¼€ Q\_shareâ€”â€”ä¸ BLIP-2/Perceiver çš„â€œè½»æŸ¥è¯¢ã€é‡ç¼–ç å™¨â€æ€è·¯ä¸€è‡´ã€‚([arXiv][1])
* å…±äº«å¯¹é½ï¼šInfoNCE/å¯¹æ¯”å­¦ä¹ ï¼ˆä»…ä½œç”¨äº Z\_shareï¼‰ã€‚([arXiv][3])
* ç§æœ‰å»ç›¸å…³ï¼šVICReg/Barlow Twins çš„åæ–¹å·®/å†—ä½™æŠ‘åˆ¶é¡¹ï¼Œé˜²æ­¢è·¨æ¨¡æ€æ··æŸ“ã€‚([arXiv][4], [Proceedings of Machine Learning Research][5])

---

# æ–¹æ¡ˆäºŒï½œâ€œç±»å‹åŒ–â€ Slot-Attentionï¼ˆå¯¹è±¡æ§½çš„å¤šæ¨¡æ€ç‰ˆï¼‰

**è¦ç‚¹**ï¼šä¸º text/img/share é¢„ç½®**å¸¦ç±»å‹åµŒå…¥**çš„ slotsï¼›æ—©æœŸæ§½åªè¯»æœ¬æ¨¡æ€ï¼ŒåæœŸæ”¾å¼€å…±äº«æ§½è·¨æ¨¡æ€è¯»å†™ï¼›å¤©ç„¶å…·å¤‡ç½®æ¢ä¸å˜çš„é›†åˆå»ºæ¨¡èƒ½åŠ›ã€‚
**å‡ºå¤„**ï¼š**Slot Attention** æå‡ºç”¨å°‘é‡å¯äº¤æ¢ slots èšåˆå¤§è§„æ¨¡è¾“å…¥ï¼›åç»­å·¥ä½œåœ¨è‡ªé€‚åº” slot æ•°é‡ä¸ç¨³å®šè®­ç»ƒä¸Šæœ‰æ‰©å±•ã€‚([arXiv][6])

**æœ€å°ä¼ªä»£ç **

```python
class TypedSlots(nn.Module):
    def __init__(self, d, n_text=6, n_img=6, n_share=4, steps=3):
        super().__init__()
        self.S_text  = nn.Parameter(torch.randn(n_text,  d))
        self.S_img   = nn.Parameter(torch.randn(n_img,   d))
        self.S_share = nn.Parameter(torch.randn(n_share, d))
        self.type_emb = nn.Embedding(3, d)  # 0=text, 1=img, 2=share
        self.xattn = MultiheadAttention(d, 8, batch_first=True)
        self.gru   = nn.GRUCell(d, d)
        self.steps = steps

    def update(self, S, KV):
        B = KV.size(0); S0 = S.unsqueeze(0).expand(B, -1, -1)
        C, _ = self.xattn(S0, KV, KV)  # è¯»å…¥
        S1 = self.gru(C.reshape(-1, C.size(-1)), S0.reshape(-1, C.size(-1)))
        return S1.reshape_as(C)

    def forward(self, txt, img, stage=0):
        B = txt.size(0)
        St = self.S_text.unsqueeze(0).expand(B, -1, -1)  + self.type_emb.weight[0]
        Si = self.S_img .unsqueeze(0).expand(B, -1, -1)  + self.type_emb.weight[1]
        Ss = self.S_share.unsqueeze(0).expand(B, -1, -1) + self.type_emb.weight[2]
        for _ in range(self.steps):
            St = self.update(St, txt)                # ä»…å†…æ¨¡æ€
            Si = self.update(Si, img)
            if stage > 0: Ss = self.update(Ss, torch.cat([txt, img], 1))
        return St, Si, Ss
```

**è®­ç»ƒè¦ç‚¹**

* ç›‘æ§â€œè·¨æ¨¡æ€æ³¨æ„åŠ›æ³„æ¼å æ¯”â€å¹¶æƒ©ç½šï¼›å…±äº«æ§½ç”¨äºä¸‹æ¸¸å¯¹é½ï¼ˆFM/CLIP ç­‰ï¼‰ã€‚Slot-Attention çš„â€œé›†åˆ/æ§½ä½â€å±æ€§å‡å°‘é¡ºåºä¾èµ–ï¼Œåˆ©äºè§£è€¦ã€‚([arXiv][6])

---

# æ–¹æ¡ˆä¸‰ï½œå…±äº«-ç§æœ‰åˆ†è§£ï¼ˆShared-Private Factorizationï¼‰

**è¦ç‚¹**ï¼šæ¯æ¨¡æ€è¾“å‡ºåˆ†åˆ«æŠ•å½±åˆ°**ç§æœ‰å­ç©ºé—´**ä¸**å…±äº«å­ç©ºé—´**ï¼›å…±äº«éƒ¨åˆ†åšè·¨æ¨¡æ€å¯¹é½ï¼Œç§æœ‰éƒ¨åˆ†åšå»ç›¸å…³/ç‹¬ç«‹æ€§çº¦æŸã€‚
**å‡ºå¤„**ï¼š**MISA** å°†æ¨¡æ€è¡¨ç¤ºæ‹†ä¸º invariantï¼ˆå…±äº«ï¼‰ä¸ specificï¼ˆç§æœ‰ï¼‰å¹¶åŠ æ­£äº¤/å»ç›¸å…³çº¦æŸï¼›**VCCA-private/DCCA** ä» CCA è§†è§’å¯¹â€œå…±äº«æ½œå˜é‡â€å»ºæ¨¡ã€‚([arXiv][7], [ACM Digital Library][8], [Proceedings of Machine Learning Research][9])

**æœ€å°ä¼ªä»£ç **

```python
class SharedPrivateProj(nn.Module):
    def __init__(self, d_in, d_priv=512, d_share=512):
        super().__init__()
        self.to_priv  = nn.Linear(d_in, d_priv)
        self.to_share = nn.Linear(d_in, d_share)

    def forward(self, H):             # H: (B, L, D)
        return self.to_priv(H), self.to_share(H)

Ht = enc_text(txt) ; Hi = enc_img(img)
Zt_p, Zt_s = proj_t(Ht); Zi_p, Zi_s = proj_i(Hi)

# losses
L_align  = info_nce(Zt_s, Zi_s)                     # å…±äº«å¯¹é½ï¼ˆæˆ– DCCA/CCA é£æ ¼ï¼‰
L_decorr = ((Zt_p.reshape(-1, Zt_p.size(-1)) - Zt_p.mean((0,1))).T @
            (Zi_p.reshape(-1, Zi_p.size(-1)) - Zi_p.mean((0,1))) ).pow(2).mean()
loss = L_task + Î±*L_align + Î²*L_decorr
```

**è®­ç»ƒè¦ç‚¹**

* å‰æœŸåªè®­ç§æœ‰ï¼ˆÎ² è¾ƒå¤§ï¼‰ï¼ŒåæœŸé€æ­¥æ‰“å¼€å…±äº«å¯¹é½ï¼ˆå¢å¤§ Î±ï¼‰ã€‚
* è‹¥æƒ³æ›´å¼ºç‹¬ç«‹æ€§ï¼Œå¯ç”¨ **HSIC** æƒ©ç½šç§æœ‰é—´ä¾èµ–ï¼ˆæ ¸ç‹¬ç«‹æ€§å‡†åˆ™ï¼‰ã€‚([Gatsby][10], [arXiv][11])

---

# æ–¹æ¡ˆå››ï½œæ¨¡æ€æ„ŸçŸ¥è·¯ç”±çš„ç¨€ç– MoE

**è¦ç‚¹**ï¼šæŠŠâ€œç§æœ‰/å…±äº«å¤„ç†â€ä¸‹æ²‰åˆ°ä¸“å®¶å±‚ï¼›ä¸ºæ–‡æœ¬ã€å›¾åƒã€å…±äº«åˆ†åˆ«é…ä¸“å®¶ç°‡ï¼Œè·¯ç”±å™¨è¯»å…¥æ¨¡æ€/ç±»å‹åµŒå…¥é€‰æ‹©ä¸“å®¶ï¼ˆTop-1/Top-2ï¼‰ï¼Œç¨€ç–æ¿€æ´»å‡å°‘ä¸²æ‰°ã€‚
**å‡ºå¤„**ï¼š**Switch Transformer** ç®€åŒ– MoE è·¯ç”±å¹¶æå‡ç¨³å®šæ€§ï¼›**V-MoE** å°† MoE æˆåŠŸåº”ç”¨åˆ°è§†è§‰ Transformerã€‚([arXiv][12], [NeurIPS Papers][13])

**æœ€å°ä¼ªä»£ç **

```python
class ModalityMoE(nn.Module):
    def __init__(self, d, experts, router):
        super().__init__()
        self.experts = nn.ModuleList(experts)  # ä¸“å®¶åˆ—è¡¨ï¼štext/img/share/...
        self.router  = router                  # è¯»å…¥ token + type_id â†’ åˆ†é… Top-k

    def forward(self, tokens, type_id):
        # router è¾“å‡ºæ¯ä¸ª token çš„ (topk_ids, gates)
        topk_ids, gates = self.router(tokens, type_id)  # (B,L,k), (B,L,k)
        out = 0
        for k in range(topk_ids.size(-1)):
            sel = topk_ids[..., k]                      # é€‰ä¸­ä¸“å®¶ id
            yk  = dispatch_and_apply(tokens, self.experts, sel)  # å¸¸è§ MoE å®ç°
            out = out + gates[..., k:k+1] * yk
        return out
```

**è®­ç»ƒè¦ç‚¹**

* ç”¨è´Ÿè½½å‡è¡¡/ç†µæ­£åˆ™ç¨³å®šè·¯ç”±ï¼›å¤šç›®æ ‡ï¼ˆFM/CLIP/KL+å‡è¡¡æŸå¤±ï¼‰å¹¶å­˜æ—¶ï¼Œé… **PCGrad/GradNorm** é™ä½æ¢¯åº¦å†²çªã€‚([arXiv][12], [NeurIPS ä¼šè®®è®°å½•][14])

---

## ç›‘æ§ä¸é²æ£’æ€§éªŒè¯ï¼ˆå¯å†™å…¥â€œå·¥ç¨‹åŒ–ä¿éšœâ€ï¼‰

* **CKA/SVCCA** è¯„ä¼°â€œåŒæ¨¡æ€ç§æœ‰é«˜ã€è·¨æ¨¡æ€ç§æœ‰ä½ã€å…±äº«è·¨æ¨¡æ€é«˜â€çš„ç›¸ä¼¼åº¦ç»“æ„ï¼›æŠŠ CKA æ›²çº¿åšæˆä»ªè¡¨æ¿ã€‚([arXiv][15], [Proceedings of Machine Learning Research][16])
* **ï¼ˆå¯é€‰ï¼‰ç½®æ¢ä¸€è‡´æ€§**ï¼šè‹¥å­˜åœ¨å¯äº¤æ¢çš„å¤šæŸ¥è¯¢/å¤šæ§½ï¼Œå¯å‚è€ƒ **DETR çš„ Hungarian åŒ¹é…**åšæœ€ä¼˜ä¸€ä¸€å¯¹é½ï¼Œä»è€Œå¯¹è¾“å…¥/æ§½ä½ç½®æ¢ä¿æŒç­‰ä»·ï¼ˆé¿å…â€œé‡æ’å¼•å‘æ¼‚ç§»â€ï¼‰ã€‚([arXiv][17])

---

## ç®€å†å¯å¤ç”¨è¡¨è¿°ï¼ˆæŒ‘ä¸€ç‰ˆï¼‰

* **å­¦æœ¯ç‰ˆ**ï¼š
  â€œæå‡ºåŸºäº **Q-Former/Perceiver æŸ¥è¯¢åº“** ä¸ **Shared-Private** åˆ†è§£çš„æ¨¡æ€è§£è€¦æ¡†æ¶ï¼šç§æœ‰åˆ†æ”¯ä»…åš**åŒæ¨¡æ€ cross-attn**ï¼Œå…±äº«åˆ†æ”¯ä»¥ **InfoNCE/CCA** å¯¹é½ï¼›è¾…ä»¥ **VICReg/Barlow** å»ç›¸å…³ä¸ **HSIC** ç‹¬ç«‹æ€§æ­£åˆ™ï¼Œæ˜¾è‘—é™ä½è·¨æ¨¡æ€æ³„æ¼ã€‚åœ¨ç¨€ç–åœºæ™¯ä¸‹å¼•å…¥ **MoE è·¯ç”±**ï¼Œå¹¶ç”¨ **PCGrad/GradNorm** ç¨³å®šå¤šç›®æ ‡ä¼˜åŒ–ã€‚â€ï¼ˆBLIP-2ã€Perceiver-IOã€Slot-Attentionã€MISAã€VCCAã€VICReg/Barlowã€Switch/V-MoE ç­‰ï¼‰([arXiv][1])

* **å·¥ç¨‹ç‰ˆ**ï¼š
  â€œè½åœ°å››å¥—è§£è€¦æ–¹æ¡ˆï¼ˆæŸ¥è¯¢åº“ã€Typed-Slotsã€Shared-Privateã€MoE è·¯ç”±ï¼‰ï¼Œ**å…ˆç§æœ‰åå…±äº«**çš„è¯¾ç¨‹å¼è®­ç»ƒ + **CKA/æ³„æ¼ç‡**ç›‘æ§ï¼›å¤§å¹…é™ä½åˆ†å—-é‡æ’å¯¼è‡´çš„è¯­ä¹‰æ¼‚ç§»ï¼Œå¹¶åœ¨ FM+CLIP+KL å¤šç›®æ ‡ä¸‹ä¿æŒæ”¶æ•›ç¨³å®šã€‚â€ï¼ˆé™„ä¸Š CKA ä¸å¯¹é½æŒ‡æ ‡ï¼‰

> æƒ³ç›´æ¥æ›¿æ¢ä½ ç°åœ¨çš„ metaqueryï¼š**ä¼˜å…ˆè¯• æ–¹æ¡ˆä¸‰ï¼ˆæœ€æ˜“æ¥å…¥ï¼‰**ï¼›è‹¥å·²ä½¿ç”¨ Q-tokenï¼Œ**æ–¹æ¡ˆä¸€**çš„å…±äº«æ¡¥å¾ˆè‡ªç„¶ï¼›éœ€è¦æ›´å¼ºâ€œæ§½ä½å¯äº¤æ¢/é¡ºåºæ— å…³â€å°±ä¸Š **æ–¹æ¡ˆäºŒ**ï¼›è¿½æ±‚å¤§æ¨¡å‹ååä¸è§£è€¦éš”ç¦»ï¼Œå¯è¿­ä»£åˆ° **æ–¹æ¡ˆå››**ã€‚

[1]: https://arxiv.org/pdf/2301.12597?utm_source=chatgpt.com "BLIP-2: Bootstrapping Language-Image Pre-training with ..."
[2]: https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf?utm_source=chatgpt.com "ğŸ¦© Flamingo: a Visual Language Model for Few-Shot Learning"
[3]: https://arxiv.org/abs/1807.03748?utm_source=chatgpt.com "Representation Learning with Contrastive Predictive Coding"
[4]: https://arxiv.org/abs/2105.04906?utm_source=chatgpt.com "VICReg: Variance-Invariance-Covariance Regularization ..."
[5]: https://proceedings.mlr.press/v139/zbontar21a/zbontar21a.pdf?utm_source=chatgpt.com "Barlow Twins: Self-Supervised Learning via Redundancy ..."
[6]: https://arxiv.org/abs/2006.15055?utm_source=chatgpt.com "Object-Centric Learning with Slot Attention"
[7]: https://arxiv.org/abs/2005.03545?utm_source=chatgpt.com "MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis"
[8]: https://dl.acm.org/doi/10.1145/3394171.3413678?utm_source=chatgpt.com "MISA: Modality-Invariant and -Specific Representations for ..."
[9]: https://proceedings.mlr.press/v28/andrew13.html?utm_source=chatgpt.com "Deep Canonical Correlation Analysis"
[10]: https://www.gatsby.ucl.ac.uk/~gretton/papers/GreBouSmoSch05.pdf?utm_source=chatgpt.com "Measuring Statistical Dependence with Hilbert-Schmidt ..."
[11]: https://arxiv.org/abs/1501.06103?utm_source=chatgpt.com "A simpler condition for consistency of a kernel ..."
[12]: https://arxiv.org/abs/2101.03961?utm_source=chatgpt.com "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
[13]: https://papers.neurips.cc/paper_files/paper/2021/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf?utm_source=chatgpt.com "Scaling Vision with Sparse Mixture of Experts"
[14]: https://proceedings.neurips.cc/paper/2020/file/3fe78a8acf5fda99de95303940a2420c-Paper.pdf?utm_source=chatgpt.com "Gradient Surgery for Multi-Task Learning"
[15]: https://arxiv.org/abs/1905.00414?utm_source=chatgpt.com "Similarity of Neural Network Representations Revisited"
[16]: https://proceedings.mlr.press/v97/kornblith19a/kornblith19a.pdf?utm_source=chatgpt.com "Similarity of Neural Network Representations Revisited"
[17]: https://arxiv.org/pdf/2005.12872?utm_source=chatgpt.com "arXiv:2005.12872v3 [cs.CV] 28 May 2020"
