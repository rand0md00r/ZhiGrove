# 多模态座舱大模型（VLA-Cabin）训练与部署资源申请书

---

## 摘要

我们拟训练并评估**多模态座舱大模型 VLA-Cabin**：在**统一潜空间**内同时处理**语音/文本、舱内视频、图像、设备与环境状态**，直接生成**座舱动作序列**（空调/座椅/灯光/媒体/车窗/应用流程等）与**可解释的自然语言反馈**。相较现有“小模型串联”（决策、车控、意图、端侧vlm等），VLA-Cabin减少感知-理解-控制链路断层，显著提升信息利用率、时序理解与复杂指令执行的一致性。

**产业趋势**：车端“VLA 上车”已进入量产阶段——**理想汽车**公开宣介“VLA 司机大模型”随新车型逐步推送，**蔚来汽车**在 2024 年推出 **NOMI GPT** 端云协同多模态大模型用于座舱交互。这些量产信号印证了**统一多模态大模型**正在成为智能座舱的主线。

**资源请求（面向持续调试）**：  
- **5 天（128×A100）代表一次完整训练周期**，常驻（64×A100）3个月。为满足**多轮迭代与消融**：
  - **整周期大窗口**：**128×A100 × 5 天/次**，**≥ 3 次/季度**（建议预留 5~6 次）；  
  - **常驻实验池**：**64×A100（全季度常驻）**，承担对齐/微调/消融/回归/RL 后训练与热修复；  
  - **季度 GPU·小时配额（A100-80GB 等效）**：**≥ 212,000 GPU·小时**（含 15% 余量）；  
- **目标交付**：统一潜空间与动作序列生成器、离线/仿真指标达标、座舱场景 DEMO。

---

## 1. 背景与行业动向

### 1.1 现状痛点（座舱域）
- **模型割裂**：决策、车控、意图、端侧vlm由多个小模型分散处理，语音、视频与设备状态难以互证，级联误差与维护成本高。  
- **视频缺席**：多依赖单帧图像与短文本，**缺少时序**导致对持续行为（入睡/手势连续性/多说话人轮次/环境渐变）理解欠稳。  
- **理解-控制断层**：上游语义难平滑映射到**座舱动作序列**（空调→灯光→媒体→车窗→应用流程），多轮交互与场景模式落地困难。

### 1.2 行业趋势与对标
- **理想汽车：VLA 司机大模型**——以多模态大模型作为车端智能中枢，强调对用户语言/场景的高一致性响应。  
- **蔚来汽车：NOMI GPT**——端云协同的多模态大模型，已在量产车型上用于座舱交互。  
- **结论**：**统一潜空间 + 端到端动作序列生成**是座舱升级的明确方向；我们具备在该赛道建立可复用“场景资产”的窗口期。

---

## 2. 项目目标与业务价值（座舱域）

### 2.1 我们的目标（VLA-Cabin 统一范式）
- **统一潜空间表征**：在共享潜空间内，同时编码**语音/文本、舱内视频、图像、设备与环境状态**，支持跨模态直接推理与纠错。  
- **端到端动作序列生成**：从多模态上下文直接生成**座舱动作 token 序列**（影院/会议/午睡/迎宾/净化等模式的精细化链路）。  
- **复杂意图与多轮偏好可执行**：处理模糊口语 + 上下文约束（“稍微冷一点”“孩子睡着了”“开始会议”），并输出自然语言解释。  
- **工程可落地**：在统一模型下，缩短链路、降低时延与集成成本，支撑 A/B 快速迭代、在线学习与跨车型横展。

### 2.2 预期业务价值
- **体验提升**：一句话完成复杂联动，降低交互步数与误触发；提供**可解释理由**，增强信任与可审计性。  
- **个性化沉淀**：统一潜空间内沉淀用户偏好（温度/灯光/音乐/香氛/应用流程），跨车型迁移形成“场景资产”。  
- **成本与效率**：以统一大模型替代多个子模型与脚本编排，**缩短推理链路**、降低集成/运维成本。  

---

## 3. 技术路线

- **冻结预训练 VLM 作为感知锚点**：继承稳健的视觉-语言对齐与多模态先验，减少大规模微调成本与感知漂移。

- **多模态 VAE → 统一潜空间**：  
  - **语音/文本**：ASR + 说话人/情绪特征，与文本共同编码为**高斯潜变量**（均值/方差）；  
  - **舱内视频/图像**：**时序感知 VAE**（时序注意力/时卷）捕捉持续行为与情境变化；  
  - **设备/环境状态**（温湿度、PM2.5、风量档、座椅、灯光、车窗/遮阳等）嵌入同维潜空间；  
  - **对齐损失**：KL 正则 + 跨模态一致性（InfoNCE/对比）压缩模态差异，构建**可检索、可组合**的统一语义坐标系。

- **可学习 Query 的跨模态特征传递** [MetaQuery](https://xichenpan.com/metaquery/)
  - 将**可学习 Query**作为“模态特征抽取器”，通过冻结模型计算语音/文本、视频、图像与设备状态的特征，传递到动作生成模块中；  
  - 融合**时序位置编码**与**座舱约束标签**（夜间静音、儿童在座、隐私等级、权限与合规规则）。
  
- **离散无噪声流匹配（DNFM）生成动作序列**  [CrossFlow](https://arxiv.org/abs/2412.15213)  [Seed_Diffusion](https://arxiv.org/pdf/2508.02193) 
  - 将座舱控制映射为**动作 token**（温度/风量/除雾/座椅加热/位置/按摩/灯光色温与亮度/音源切换与音量/车窗开度/香氛/应用流程步骤等）；  
  - **DNFM**学习从“上下文潜表征”到“目标动作序列”的**连续流**（无噪声、速度场回归、路径一致性），较扩散法**收敛稳、采样快、时延低**；  
  - **多头输出**：主头输出动作序列，副头生成**自然语言解释**。
  
- **多模态 RL 后训练（指令与偏好对齐）** [CoT_VLA](https://arxiv.org/pdf/2503.22020)
  - 数据与环境：历史座舱交互日志 + 座舱交互仿真器/应用流程模拟器；  
  - 奖励：任务完成率、步数/时延、误触发、舒适度、内容与权限合规、偏好一致性；关键情境设**代价/护栏**（夜间音量阈值、行车中屏幕限制、隐私遮罩）；  
  - 偏好对齐：RLAIF/DPO-style 以语言/偏好反馈优化“模糊口语 + 多轮约束”的执行一致性；  
  - 稳定性：RL 阶段**VLM 冻结、VAE 轻调（LoRA/Adapter）**，重点优化路由与策略。

---

## 4. 数据与评测（座舱域）

### 4.1 数据构成与来源（按“预训练 / 监督微调”分层）
为保证模型既有广谱多模态能力、又能贴合座舱业务，我们将数据划分为**预训练（开源）**与**监督微调（开源 + 内部）**两层。

**A. 预训练（全部采用开源数据集）**
- **VLA（Vision–Language–Action）类数据集**  
  - 含“指令/描述 ↔ 动作/控制轨迹/程序化步骤”的成对样本，可学习**从语义到动作序列**的对齐与规划能力。  
  - 用途：预习“语言→动作”的同形建模与序列解码范式，为座舱动作 token 化与DNFM解码打基础。  
- **图文对数据集**  
  - 大规模图像–文本配对语料（说明/问答/描述），提升**视觉–语言对齐**与开放域语义覆盖。  
  - 用途：打牢冻结 VLM 的语义锚点，增强多模态表示的可迁移性与鲁棒性。  
- **视频–文本数据集**  
  - 含**时序**叙述/字幕/步骤的开源视频语料（egocentric/第三人称混合），学习**跨帧依赖**与**动作先后关系**。  
  - 用途：为舱内视频的**持续行为/多轮上下文**建模提供时序先验。  
- **语音/音频–文本数据集**  
  - 大规模语音转写、说话人与情绪标注、音频事件（鸣笛/哭声/环境噪声等）开源集合。  
  - 用途：增强**嘈杂环境下 ASR 稳健性**、说话人/情绪识别与**音频事件检测**能力。  
- **预训练数据治理（统一执行）**  
  - **去重与质量筛选**：感知重复检测（感知哈希/向量召回）、极短/极长样本裁剪、低质字幕过滤；  
  - **合规与隐私**：PII/敏感词稳健识别与替换；NSFW/版权风险过滤；  
  - **统一格式与标注**：全部样本转为**\{多模态输入, 目标文本/动作序列/事件\}**的统一样式，便于后续 VAE 编码与训练管线；  
  - **混合采样**：按“VLA : 图文 : 视频 : 语音 = **2 : 2 : 1 : 1**（可调）”进行温度采样与难例上采样。

**B. 监督微调（SFT：高质量开源 + 公司内部业务数据）**
- **高质量开源**  
  - 类型：**多模态指令跟随**（图像/视频问答、视觉定位与步骤执行）、**视频指令理解**、**音频事件检测/音频问答**、**对话式语音助手**等。  
  - 价值：将通用能力收束为**“指令→动作序列/解释”**的格式，提升可执行性与一致性。  
- **公司内部业务数据（严格合规）**  
  - 来源：真实**座舱交互日志**（语音/舱内视频/设备与环境状态/应用流程）、**座舱控制轨迹**（空调/座椅/灯光/媒体/车窗/香氛等）、多说话人/多乘员上下文。  
  - 标注与对齐：将历史交互**重放对齐**为“\{多模态上下文\} → \{动作 token 序列 + 解释\}”；补充**场景模式**（影院/会议/午睡/迎宾/净化）模板与偏好标签。  
  - 价值：完成**域内迁移**与**个性化/偏好对齐**，缩短从实验到量产的落差。  
- **SFT 数据配比**  
  - 高质量开源 : 内部业务 ≈ **1 : 1** 起步；若域内指标不足，逐步提高内部权重（至 **1 : 2**）。  
  - 模块化增量：动作稀缺类（如香氛/按摩/隐私遮罩）**定向上采样**；误触发高发类**难例回放**。

> 备注：所有内部数据全程执行**脱敏、访问分级、用途限定与留痕审计**；对第三方开源数据保留许可证与来源记录，确保可追溯。

---

### 4.2 指标（离线 + 仿真/在线）
- **单轮/多轮成功率**、**平均操作步数**、**响应时延 P95**、**过召率**；  
- **场景模式命中率**（影院/会议/午睡/迎宾/净化等）、**个性化命中率**；  
- **跨模态对齐**：图文/视听检索 R@k、跨模态NCE；**动作序列质量**：步骤完整率、逆序与冲突率。

---

## 5. 计算资源与计划（面向持续调试）

### 5.1 资源请求（A100-80GB 等效）
**目标**：不仅完成“**128×A100×5 天**”的**单次整周期训练**，更要支撑**多轮迭代/消融/RL 后训练/回归**直至达标。

**GPU**
1) **整周期大窗口（Full Cycle）**  
   - 规模：**128×A100 × 5 天/次**  
   - 数量：**≥ 3 次/季度**（建议预留 5~6 次）  
   - 用途：从零到收敛的完整训练、关键版本里程碑（M2/M3/M4 前）。  
2) **常驻实验池（Resident Pool）**  
   - 规模：**64×A100（全季度常驻）**  
   - 用途：DNFM 与路由/策略头微调、跨模态对齐、消融、回归、RL 后训练、数据/解码压测与热修复。  


**CPU / 内存 / I/O / 存储**
- **CPU**：**3,000–5,000 vCPU**（RL 仿真、日志回放、特征抽取、数据清洗并行）。  
- **内存**：**4–8 TB RAM**（并发解码、缓存与高吞吐 DataLoader）。  
- **存储**：**100–150 TB** 冷热分层（原始多媒体、特征、检查点、评测产物）；对象存储 + 本地 **NVMe** 缓存；单作业 I/O 吞吐 **≥ 10–20 GB/s**。  
- **网络**：节点内 **NVLink**；跨机架 **InfiniBand ≥ 200–400 Gbps**。  
- **软件栈**：PyTorch 2.4 / CUDA 12.x，FSDP/ZeRO，bfloat16；SLURM/Ray；WebDataset/TFRecord 分片与校验。

### 5.2 GPU·小时预算与拆解（按季度 90 天计）

| 项目 | 规模 | 次数 | 小计（GPU·小时） |
|---|---|---:|---:|
| 常驻实验池 | 64×A100 × 24h × 90 天 | — | 64 × 24 × 90 = **138,240** |
| 整周期训练 | 128×A100 × 5 天 | 3 | 15,360 × 3 = **46,080** |
| 故障回滚/突发余量 | — | — | **27,648**（约 15% 余量） |
| **合计** | — | — | **≈ 212,000** |

### 5.3 排期与并发策略
- **整周期大窗口**：季度内**预排 3–4 个“128×A100×5 天”**窗口（错峰），用于主要版本的里程碑训练与收敛。  
- **常驻长流水线**：**64×A100** 贯穿全季度，承担**对齐/微调/消融/回归/RL**；确保**每天都有可验证增量**。  
- **并发上限**：重作业并发 ≤ 2；常驻与整周期并行时，限速数据面（带宽 QoS + 就近缓存）。  
- **断点与回滚**：Checkpoint **每 2 小时**；失败立即回滚上个稳定点；模型/数据以 **SemVer + DataHash** 标注。

### 5.4 工程与质量保障
- **数据面**：多媒体解码异步化；特征与原始数据双轨缓存；分片 CRC 校验与采样对齐；易错样本白名单回放。  
- **训练面**：FSDP + 激活检查点；等效批量 **≥ 1–2k**；bfloat16；学习率热启与 Auto-resume；训练看板（吞吐/显存/失活率/有效步长）。  
- **评测面**：日更回归基线（单/多轮成功率、步数、P95 时延、误触发、解释一致性、个性化命中率）；**周报趋势看板**与异常归因。  
- **安全与合规**：权限、未成年、夜间、分心等护栏常开；日志脱敏与访问分级；全链路可追溯审计。

---

## 6. 里程碑与交付

- **M1（T+1–2 周）**：统一潜空间/对齐效果可视化；跨模态检索 DEMO；数据治理与合规清单。  
- **M2（T+3–4 周）**：DNFM 动作序列生成收敛；离线评测达标（单/多轮成功率、步数、P95 时延、误触发）。  
- **M3（T+5–6 周）**：仿真/在线沙箱评测达标；输出**解释样例集**与**护栏报告**；A/B 方案与回归基线固化。  
- **M4（T+7–8 周）**：灰度联调（封闭/限定场景）；交付 DEMO 视频、技术白皮书与上线路线图。

---

## 7. 风险与对策

- **长尾与歧义口语**：视频时序 + 情绪/说话人建模 + 偏好反馈（RLAIF）缓解；疑似歧义触发澄清模板。  
- **误触发与合规**：权限/分心/夜间/未成年人护栏内嵌；回退最小扰动原则；高风险动作需二次确认。  
- **工程复杂度**：统一模型与路由器抽象简化集成；可插拔 Adapter 支持车型/硬件差异；规范化指标与报警。  
- **数据与隐私**：分级访问、端侧脱敏、加密审计；合规场景数据分隔与留痕；第三方数据合规备案。

---

## 8. 产出与 ROI

- **模型与代码**：VLA-Cabin 统一潜空间、DNFM 动作生成器、RL 后训练管线。  
- **场景资产化**：“影院/小憩/迎宾/运动”等**场景模式库**与偏好画像，跨车型复用，形成平台化扩展能力。  
- **商业价值**：显著缩短交互路径、提升满意度与留存；降低多模型集成/运维成本；形成可审计解释与合规框架。  
- **对标趋势**：与**理想 VLA**、**蔚来 NOMI GPT**方向一致，具备量产落地与差异化空间。

---

## 附：申请单关键信息（占位）

- **算力排期**：\[季度\] 内预留 **3–4 个整周期窗口（128×A100×5 天）**；**64×A100 常驻**。  
- **数据路径与容量**：\[对象存储桶/权限/配额\]；缓存策略：\[NVMe/分片/CRC\]。  
- **网络与机房**：节点 NVLink；IB ≥ 200–400 Gbps；机房/机架：\[名称\]。  
- **负责人/安全责任人**：\[姓名/部门\]；**合规联系人**：\[姓名/部门\]。  
- **评审与里程碑**：M1/M2/M3/M4 对应日期与验收指标。  
- **风险与回滚**：Checkpoint 间隔 2 小时；SemVer + DataHash；预留 15% GPU·小时。  

> 需要可额外提供：**Word/Slides 版**、KPI 看板页（含阈值与 A/B 对照）、详细预算拆解与排期甘特图。
