### 封面页：

**标题：**

* 用 TRM 提升结构化输出任务的可靠性
* ——面向 Function Call 与 VLA 的递归推理优化方案

**副标题 & 基本信息：**

* 部门 / 项目名
* 汇报人 / 日期

---

### 目录页（可选）

1. 业务动机：结构化输出的痛点
2. TRM 原理与性能优势
3. Function Call 任务的 TRM 优化方案
4. VLA 任务的 TRM 优化方案
5. 关键问题与风险分析
6. 小结与下一步计划

---

## 1. 业务动机：为什么需要“可修正”的结构化输出机制？

**Slide 1：结构化输出任务场景**

* **Function Call 场景：**

  * LLM 需要输出固定格式 JSON（函数名 + 参数字段）；
  * 要求：字段齐全、类型正确、可直接调用业务 API。
* **VLA 场景：**

  * VLM / VLA 输出固定长度动作序列（关节角、离散指令 token 等）；
  * 要求：维度固定、范围合法、连续动作可执行。

---

**Slide 2：现有方案的痛点**

* 直接让 LLM 一步生成结构化输出，常见问题：

  * JSON 括号缺失、字段名错误、值类型不符；
  * 动作向量维度错、越界、不连续导致机器人失败。
* 即使用了 CoT（思维链）提示：

  * 解释写得很长，但最后一行结构仍然可能不合法；
  * 多调用几次 LLM 做自检，成本高、延迟大。
* **结论：**

  * 我们需要一种**可以“多想几步、逐步修正答案”的机制**，专门面向结构化输出。

---

## 2. TRM 原理分析与性能优越性

**Slide 3：TRM 的核心思想**

* Tiny Recursive Model (TRM)：

  * 一个**很小的两层网络**（级别 7M 参数）；
  * 维护三个量：

    * 输入表示 (x)：题目 / 场景的 embedding；
    * 潜在状态 (z)：内部“思考状态”；
    * 当前答案 (y)：当前预测的解（可以是离散 token 或连续向量）。
* 推理流程（递归）：

  * 在固定的 (x) 下，多次更新 (z)（高频 latent 推理）；
  * 再更新一次 (y)（改进答案）；
  * 如此循环 K 步，每一步都让答案更接近正确结果。

---

**Slide 4：TRM 的训练与性能优势**

* **深监督（deep supervision）：**

  * 每一步的中间答案 (y_k) 都有监督，而不是只看最后一步；
  * 让模型学会“如何一步步把答案修正正确”。
* **性能优越性（定性描述）：**

  * 在大量谜题 / 复杂推理任务上，小 TRM 通过递归能超过体积大很多的 LLM；
  * 说明：**“多次小步修正”有时比“一步大预测”更强。**
* **对我们场景的意义：**

  * TRM 适合做“结构化输出 + 可多步修正”的任务：

    * JSON 填空、动作序列 refinement、状态空间较小但结构严谨。

---

## 3. Function Call 任务：TRM 优化方案

**Slide 5：Function Call 现状与问题**

* 现有流程：

  * LLM 直接输出函数调用 JSON（可能配合 CoT 提示）；
  * 下游需要做 JSON 解析和大量错误兜底。
* 痛点：

  * 稍微复杂一点的 schema，错误率显著上升；
  * 出错往往不是“理解不对”，而是**细节填错 / 格式错**。

---

**Slide 6：Function Call + TRM 的整体架构**

* **LLM 作为“语义理解层”：**

  * 输入：用户自然语言 / 上下文；
  * 输出：

    * 语义向量（latent embedding），或
    * 简短结构化描述（内部 CoT / 约束信息）。
* **TRM 作为“结构化推理头”：**

  * 输入：

    * LLM 的表示 (x)（文本或 latent）；
    * 初始答案 (y_0)（粗糙 JSON 草稿，或全零 JSON embedding）；
  * 通过多步递归更新：

    * 每一步检查并修正字段、类型、取值；
    * 最终输出一个结构合法的 JSON。

---

**Slide 7：Function Call 优化的训练思路**

* 数据构造：

  * 输入：真实用户 query + 上下文；
  * 标签：最终正确的函数调用 JSON。
* 训练方式：

  * 冻结 LLM，训练 TRM + 映射层：

    * 对每个递归步 (y_k)，计算 JSON 字段级别的 CE 或回归 loss；
    * 可以显式设计“字段缺失 / 类型错误”的 penalty。
* 评价指标：

  * JSON 合法率、字段完整率、调用成功率；
  * 与“只用 LLM” / “更大 LLM”做对比。

---

## 4. VLA 任务：TRM 优化方案

**Slide 8：VLA 结构化输出特点**

* VLA 模型输出：

  * 固定长度动作向量（如 T 步 × 关节维度）；
  * 或固定长度离散动作 token 序列。
* 现有问题：

  * 某些时间步动作离谱（抖动、越界）；
  * 长序列累积误差导致任务失败；
  * 重新跑一次推理成本高，不能简单“多采样几次”。

---

**Slide 9：VLA + TRM 的整体架构**

* **感知 / 编码层：**

  * VLM（视觉 + 语言 + 状态）编码成 latent 表示 (x)；
* **初始动作预测：**

  * 原有 VLA / Flow Matching 模块给出初始动作序列 (y_0)；
* **TRM 作为“动作 refinement 头”：**

  * 输入：

    * 场景 latent (x)、初始动作 (y_0)；
  * 多步递归：

    * 更新 latent 状态 (z)，逐步修正动作序列；
    * 约束动作维度、范围、平滑性。
* 输出：

  * 最终 refined 的固定长度动作序列，用于控制机器人。

---

**Slide 10：VLA 优化的训练思路**

* 数据：

  * (观测、指令) → 专家示教动作 / 高质量政策动作序列。
* 训练：

  * 冻结（或小范围微调）原 VLA backbone 和 Flow head；
  * 训练 TRM 去最小化每步动作与专家动作的差异（MSE / smoothness loss）；
  * 可以对中间步 (y_k) 也施加监督，让 TRM 学会“怎么一步步纠偏”。
* 指标：

  * 任务成功率（成功完成抓取 /导航/整理）；
  * 动作平滑度、越界率；
  * 运行时延迟 vs baseline。

---

## 5. 可能存在的问题 & 风险讨论

**Slide 11：latent 推理 vs CoT**

* **CoT 的优点：**

  * 可解释性好，适合人类阅读与调试。
* **latent 推理的优点：**

  * 直接对“结构化输出”本身优化；
  * 每步计算成本小，可以多步递归；
  * 对 VLA 这类连续控制任务，更自然适配。
* **潜在问题：**

  * latent 空间不可直观解释，debug 不如 CoT 直观；
  * 需要设计好 latent 维度与映射，否则信息损失或训练难收敛。
* **综合：**

  * CoT 更像“嘴上推理”，latent TRM 更像“大脑内部算细节”；
  * 对我们这种**“结果给机器看”**的结构化任务，优先在 latent 里做推理更合适。

---

**Slide 12：为什么要加 TRM 推理头？直接用 LLM 不行吗？**

* 现状：

  * LLM 已经很强，但一个模型同时做“理解 + 推理 + 格式控制”，
  * 对结构化任务稍微提一点点精度，往往要换更大模型或更复杂 prompt。
* 加 TRM 的好处：

  * **职责分离：**

    * LLM 负责“看懂问题”；
    * TRM 专门负责“在固定格式空间里多步修正答案”。
  * **效率更高：**

    * 增加的是一个 7M 级小模型 + 多步迭代，比换更大 LLM 省算力；
  * **优化更精准：**

    * 可以专门针对 JSON/动作这些指标做训练，不影响 LLM 的通用能力。
* 如何证明必要性（实验设计）：

  * 三组对比：

    1. 只用现有 LLM；
    2. 更大 LLM / 更复杂 CoT；
    3. LLM + TRM 推理头；
  * 比较：结构化输出错误率、任务成功率、算力成本。

---

**Slide 13：整体风险与应对策略**

* 风险点：

  * 训练复杂度增加：需要多步展开 + 深监督；
  * 推理延迟增加：递归步数带来的额外计算；
  * 与现有系统集成：接口设计、灰度发布与回退。
* 应对策略：

  * 从小规模原型开始（单一 function call / 单一 VLA 子任务）；
  * 优先做“Frozen LLM + 只训 TRM”版本；
  * 控制递归步数在 3~5 步，评估性能-延迟 trade-off；
  * 保留无 TRM 的原路径，方便 A/B 灰度和紧急回滚。

---

### 收尾页：小结与下一步计划（可选）

**Slide 14：小结**

* 我们的目标：

  * 面向 function call & VLA 两类**结构化输出任务**，
  * 用 TRM 的递归推理机制给现有模型加一层“可训练的纠错与细节优化”。
* 预期收益：

  * 提升格式合法率、任务成功率与鲁棒性；
  * 同时保持算力开销可控。

**Slide 15：下一步计划**

* 短期（1–2 个月）：

  * 完成 function call 场景的 TRM 原型实现与评估；
  * 对比只 LLM / 大 LLM / LLM+TRM 三种方案。
* 中期（3–6 个月）：

  * 将 TRM 扩展到 1~2 个关键 VLA 子任务；
  * 探索 latent 推理与 flow-matching、视频 VLM 的更紧密结合。
* 长期：

  * 将 “LLM + TRM 推理头” 打造成我们内部的通用结构化输出解决方案，
  * 在更多机器人与 API 场景中复用。
