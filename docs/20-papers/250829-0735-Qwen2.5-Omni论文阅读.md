---
title: Qwen2.5-Omni论文阅读
created: 2025-09-07 17:02
updated: 2025-09-07
origin: week-35
type: paper
status: draft
tags: []
links: []
---


## Raw Notes


[论文连接](https://arxiv.org/pdf/2503.20215)

# 2. Architecture

## 2.1 Overview

Figure 2 中展示了Qwen2.5-Omni采用的Thinker-Talker 架构。

- Thinker用于处理和理解多模态的输入，包括文本，语音，视频（无音频），生成高纬度的表示，以及对应的文本；
- Talker采用一个流管理（streaming manner）处理高维表征和Thinker输出的文本，并输出成离散的token。
- Thinker是一个Transformer 解码器的结构，并配有编码器用于处理多模态信息的输入；
- Talker 是一个双轨自回归Transformer解码器架构（Dual-track autoregressive Transformer Decoder architecture），借鉴了Mini-Omni模型。
- 在训练和推理中，talker直接接收来自于Thinker的高维表征，并共享所有Thinker的历史上下文信息。

## 2.2 Perceivation

### 文本、音频、图像、视频(无音频)输入处理

- 文本：使用Qwen的tokenizer，采用byte-level的byte-pair编码，词表长度151,643；
- 音频：包括常规音频和video音频，重新采样到16kHz的频率，并将原始波形转换到128通道的梅尔频谱图，窗口大小为25ms，hop size为10ms；编码器使用的是Qwen2-Audio，每一帧的音频表示对应了大概40ms的片段；
- 图像：采用Qwen2.5VL的ViT，675m参数，能够编码图像和video；视觉编码器使用图像和视频混合训练的方案；
- 视频：采用动态帧率对视频进行采样，以适应音频采样率的同时尽可能完整的保留商品信息。为了保持一致性，每个图像被视为两个相同对的帧；

### Video and TMRoPE

- 提出了音频和视频的时间交错算法，以及TMRoPE位置编码；TMRoPE对多模态输入的三维信息进行编码，即具有绝对时间位置的多模态旋转位置嵌入（M-RoPE）；
- TMRoPE将原来的旋转位置编码解构为三部分：时间、高度和宽度；
- 对于文本输入，采用相同的位置ID，使M-RoPE退化为1D-RoPE；
- 对于音频输入，也采用相同的位置ID，并且引入绝对时间位置编码，一个时间ID对应40ms；
- 对于图像输入，suddenly./SuSS
