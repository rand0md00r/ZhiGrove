import{_ as i,c as t,o as e,ag as a}from"./chunks/framework.CQuhCYrb.js";const x=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"00-inbox/week-50/251211-1650-JiT论文-视频要点.md","filePath":"00-inbox/week-50/251211-1650-JiT论文-视频要点.md"}'),_={name:"00-inbox/week-50/251211-1650-JiT论文-视频要点.md"};function p(o,l,r,n,s,h){return e(),t("div",null,[...l[0]||(l[0]=[a("<ol><li><p>流形假设</p><ul><li>高维空间的图像数据，不会零散的分布在整个高纬空间，而是依附在一个低维的流形上。这个流形是数据的专属区域，只包含数据的核心信息，比如物体的形状，颜色，剔除了高维的冗余和噪声。</li><li>图像数据看起来是高维的，但本质上是低维的，像高维空间卷起来的一张低维纸，所有数据都落在这张纸上。</li></ul></li><li><p>传统扩散模型的弊端</p><ul><li>epsilon-pred，预测epsilon的方法（sd类），在高维下会失效，在预测整个高纬空间中的数据分布时，模型需要记住每个patch的特征，需要广大的网络宽度与冗余参数；</li><li>v-pred，预测数据噪声混合流速，但带噪量v需要横跨整个高维空间，模型需要学习的范式更加复杂，也需要高容量，训练难度也高；</li></ul></li><li><p>JiT 贡献</p><ul><li>JiT直接预测干净数据（x-prediction）</li><li>无需模型记高维噪声细节；</li><li>从带噪输入筛选低维干净数据特征；</li><li>降低模型容量需求，避免高维空间维度灾难；</li><li>契合精准提取核心信息逻辑；</li></ul></li><li><p>JiT - 核心预测目标 （x- prediction）</p><ul><li>输入带噪数据 z_t (z_t = t·x + （1-t）·epsilon), 模型直接输出干净数据预测值x_theta（x_theta = net_theta(z_t, t)）， 无需反推；</li><li>依流型假设，模型筛流形核心特征；</li><li>隐藏层低于 patch维仍精准预测；</li><li>用 v-loss优化，x_theta 转 v_theta保稳定；</li><li>不改变直接预测 x 逻辑，免复杂加权；</li></ul></li><li><p>JiT - 极简架构设计（大 patch Transformer）</p><ul><li>图像划非重叠大 patch，降序列长度；</li><li>256 x 256 用16x16 patch（长256）；</li><li>512 x 512 用32x32 patch（长256）；</li><li>核心组件仅线性嵌入，无额外模块；</li><li>无Tokenizer、预训练等，像素端到端训；</li><li>大 patch 保留局部语义完整性，减计算量，分辨率不影响长度；</li><li>1024x1024 与 256x256 计算量相当</li></ul></li><li><p>JiT - 瓶颈嵌入；</p><ul><li>patch 嵌入层加“降维 + 升维”线性瓶颈；</li><li>高维patch 先降维d‘，再升维至隐藏层（将高维patch（如16x16x3=768）先降到低维的d‘（可低至16维），再升到transformer的隐藏层的维度）；</li><li>JiT用logit- normal采样t调噪声水平；</li><li>噪声调度最优 miu = -0.8 ，衡稳与质量；</li><li>瓶颈促进模型学习低纬特征，契合流型假设；</li><li>瓶颈 32 - 512 维度时，FID提升1.3</li><li>瓶颈低至 16 维，无性能退化；</li></ul></li><li><p>训练与推理</p><ul><li>训练流程； <ul><li>核心步骤 采样t -&gt; 生成z_t = t·x + (1 - t) · epsilon -&gt; 模型输出x_theta -&gt; 计算v_theta = (x_theta - z_t)/(1 - t) -&gt; v-loss (L = E_t,x,epsilon || v_theta - v ||^2)优化 -&gt; 更新参数</li><li>组件状态 Transformer权重可训练，patch嵌入层（linear patch embedding）/位置编码（positional embedding）参数固定；</li><li>关键操作 含v-loss计算与梯度反向传播更新（更新Transformer核心权重与线性预测头权重）</li></ul></li><li>推理流程 <ul><li>核心步骤 初始化z_0（噪声，z_0 ~ N(0, I) -&gt; t从0到1迭代 —&gt; 模型输出x_theta -&gt; 计算v_theta=(x_theta - z_t)/(1-t) -&gt; ODE求解 z_t+delta t -&gt; t = 1时输出x_theta</li><li>组件状态 所有组件（Transformer、patch 嵌入层、位置编码、线性预测头）权重固定，仅执行前向计算</li><li>关键操作 含50步Heun ODE求解（d z_t / dt = v_theta(z_t, t)），保证生成平滑；</li></ul></li></ul></li></ol>",1)])])}const d=i(_,[["render",p]]);export{x as __pageData,d as default};
