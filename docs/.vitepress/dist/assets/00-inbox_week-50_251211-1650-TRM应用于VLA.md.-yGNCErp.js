import{_ as i,c as t,o as n,ag as o}from"./chunks/framework.CQuhCYrb.js";const M=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"00-inbox/week-50/251211-1650-TRM应用于VLA.md","filePath":"00-inbox/week-50/251211-1650-TRM应用于VLA.md"}'),u={name:"00-inbox/week-50/251211-1650-TRM应用于VLA.md"};function r(p,l,e,a,s,g){return n(),t("div",null,[...l[0]||(l[0]=[o('<h3 id="封面页" tabindex="-1">封面页： <a class="header-anchor" href="#封面页" aria-label="Permalink to &quot;封面页：&quot;">​</a></h3><p><strong>标题：</strong></p><ul><li>用 TRM 提升结构化输出任务的可靠性</li><li>——面向 Function Call 与 VLA 的递归推理优化方案</li></ul><p><strong>副标题 &amp; 基本信息：</strong></p><ul><li>部门 / 项目名</li><li>汇报人 / 日期</li></ul><hr><h3 id="目录页-可选" tabindex="-1">目录页（可选） <a class="header-anchor" href="#目录页-可选" aria-label="Permalink to &quot;目录页（可选）&quot;">​</a></h3><ol><li>业务动机：结构化输出的痛点</li><li>TRM 原理与性能优势</li><li>Function Call 任务的 TRM 优化方案</li><li>VLA 任务的 TRM 优化方案</li><li>关键问题与风险分析</li><li>小结与下一步计划</li></ol><hr><h2 id="_1-业务动机-为什么需要-可修正-的结构化输出机制" tabindex="-1">1. 业务动机：为什么需要“可修正”的结构化输出机制？ <a class="header-anchor" href="#_1-业务动机-为什么需要-可修正-的结构化输出机制" aria-label="Permalink to &quot;1. 业务动机：为什么需要“可修正”的结构化输出机制？&quot;">​</a></h2><p><strong>Slide 1：结构化输出任务场景</strong></p><ul><li><p><strong>Function Call 场景：</strong></p><ul><li>LLM 需要输出固定格式 JSON（函数名 + 参数字段）；</li><li>要求：字段齐全、类型正确、可直接调用业务 API。</li></ul></li><li><p><strong>VLA 场景：</strong></p><ul><li>VLM / VLA 输出固定长度动作序列（关节角、离散指令 token 等）；</li><li>要求：维度固定、范围合法、连续动作可执行。</li></ul></li></ul><hr><p><strong>Slide 2：现有方案的痛点</strong></p><ul><li><p>直接让 LLM 一步生成结构化输出，常见问题：</p><ul><li>JSON 括号缺失、字段名错误、值类型不符；</li><li>动作向量维度错、越界、不连续导致机器人失败。</li></ul></li><li><p>即使用了 CoT（思维链）提示：</p><ul><li>解释写得很长，但最后一行结构仍然可能不合法；</li><li>多调用几次 LLM 做自检，成本高、延迟大。</li></ul></li><li><p><strong>结论：</strong></p><ul><li>我们需要一种<strong>可以“多想几步、逐步修正答案”的机制</strong>，专门面向结构化输出。</li></ul></li></ul><hr><h2 id="_2-trm-原理分析与性能优越性" tabindex="-1">2. TRM 原理分析与性能优越性 <a class="header-anchor" href="#_2-trm-原理分析与性能优越性" aria-label="Permalink to &quot;2. TRM 原理分析与性能优越性&quot;">​</a></h2><p><strong>Slide 3：TRM 的核心思想</strong></p><ul><li><p>Tiny Recursive Model (TRM)：</p><ul><li><p>一个<strong>很小的两层网络</strong>（级别 7M 参数）；</p></li><li><p>维护三个量：</p><ul><li>输入表示 (x)：题目 / 场景的 embedding；</li><li>潜在状态 (z)：内部“思考状态”；</li><li>当前答案 (y)：当前预测的解（可以是离散 token 或连续向量）。</li></ul></li></ul></li><li><p>推理流程（递归）：</p><ul><li>在固定的 (x) 下，多次更新 (z)（高频 latent 推理）；</li><li>再更新一次 (y)（改进答案）；</li><li>如此循环 K 步，每一步都让答案更接近正确结果。</li></ul></li></ul><hr><p><strong>Slide 4：TRM 的训练与性能优势</strong></p><ul><li><p><strong>深监督（deep supervision）：</strong></p><ul><li>每一步的中间答案 (y_k) 都有监督，而不是只看最后一步；</li><li>让模型学会“如何一步步把答案修正正确”。</li></ul></li><li><p><strong>性能优越性（定性描述）：</strong></p><ul><li>在大量谜题 / 复杂推理任务上，小 TRM 通过递归能超过体积大很多的 LLM；</li><li>说明：<strong>“多次小步修正”有时比“一步大预测”更强。</strong></li></ul></li><li><p><strong>对我们场景的意义：</strong></p><ul><li><p>TRM 适合做“结构化输出 + 可多步修正”的任务：</p><ul><li>JSON 填空、动作序列 refinement、状态空间较小但结构严谨。</li></ul></li></ul></li></ul><hr><h2 id="_3-function-call-任务-trm-优化方案" tabindex="-1">3. Function Call 任务：TRM 优化方案 <a class="header-anchor" href="#_3-function-call-任务-trm-优化方案" aria-label="Permalink to &quot;3. Function Call 任务：TRM 优化方案&quot;">​</a></h2><p><strong>Slide 5：Function Call 现状与问题</strong></p><ul><li><p>现有流程：</p><ul><li>LLM 直接输出函数调用 JSON（可能配合 CoT 提示）；</li><li>下游需要做 JSON 解析和大量错误兜底。</li></ul></li><li><p>痛点：</p><ul><li>稍微复杂一点的 schema，错误率显著上升；</li><li>出错往往不是“理解不对”，而是<strong>细节填错 / 格式错</strong>。</li></ul></li></ul><hr><p><strong>Slide 6：Function Call + TRM 的整体架构</strong></p><ul><li><p><strong>LLM 作为“语义理解层”：</strong></p><ul><li><p>输入：用户自然语言 / 上下文；</p></li><li><p>输出：</p><ul><li>语义向量（latent embedding），或</li><li>简短结构化描述（内部 CoT / 约束信息）。</li></ul></li></ul></li><li><p><strong>TRM 作为“结构化推理头”：</strong></p><ul><li><p>输入：</p><ul><li>LLM 的表示 (x)（文本或 latent）；</li><li>初始答案 (y_0)（粗糙 JSON 草稿，或全零 JSON embedding）；</li></ul></li><li><p>通过多步递归更新：</p><ul><li>每一步检查并修正字段、类型、取值；</li><li>最终输出一个结构合法的 JSON。</li></ul></li></ul></li></ul><hr><p><strong>Slide 7：Function Call 优化的训练思路</strong></p><ul><li><p>数据构造：</p><ul><li>输入：真实用户 query + 上下文；</li><li>标签：最终正确的函数调用 JSON。</li></ul></li><li><p>训练方式：</p><ul><li><p>冻结 LLM，训练 TRM + 映射层：</p><ul><li>对每个递归步 (y_k)，计算 JSON 字段级别的 CE 或回归 loss；</li><li>可以显式设计“字段缺失 / 类型错误”的 penalty。</li></ul></li></ul></li><li><p>评价指标：</p><ul><li>JSON 合法率、字段完整率、调用成功率；</li><li>与“只用 LLM” / “更大 LLM”做对比。</li></ul></li></ul><hr><h2 id="_4-vla-任务-trm-优化方案" tabindex="-1">4. VLA 任务：TRM 优化方案 <a class="header-anchor" href="#_4-vla-任务-trm-优化方案" aria-label="Permalink to &quot;4. VLA 任务：TRM 优化方案&quot;">​</a></h2><p><strong>Slide 8：VLA 结构化输出特点</strong></p><ul><li><p>VLA 模型输出：</p><ul><li>固定长度动作向量（如 T 步 × 关节维度）；</li><li>或固定长度离散动作 token 序列。</li></ul></li><li><p>现有问题：</p><ul><li>某些时间步动作离谱（抖动、越界）；</li><li>长序列累积误差导致任务失败；</li><li>重新跑一次推理成本高，不能简单“多采样几次”。</li></ul></li></ul><hr><p><strong>Slide 9：VLA + TRM 的整体架构</strong></p><ul><li><p><strong>感知 / 编码层：</strong></p><ul><li>VLM（视觉 + 语言 + 状态）编码成 latent 表示 (x)；</li></ul></li><li><p><strong>初始动作预测：</strong></p><ul><li>原有 VLA / Flow Matching 模块给出初始动作序列 (y_0)；</li></ul></li><li><p><strong>TRM 作为“动作 refinement 头”：</strong></p><ul><li><p>输入：</p><ul><li>场景 latent (x)、初始动作 (y_0)；</li></ul></li><li><p>多步递归：</p><ul><li>更新 latent 状态 (z)，逐步修正动作序列；</li><li>约束动作维度、范围、平滑性。</li></ul></li></ul></li><li><p>输出：</p><ul><li>最终 refined 的固定长度动作序列，用于控制机器人。</li></ul></li></ul><hr><p><strong>Slide 10：VLA 优化的训练思路</strong></p><ul><li><p>数据：</p><ul><li>(观测、指令) → 专家示教动作 / 高质量政策动作序列。</li></ul></li><li><p>训练：</p><ul><li>冻结（或小范围微调）原 VLA backbone 和 Flow head；</li><li>训练 TRM 去最小化每步动作与专家动作的差异（MSE / smoothness loss）；</li><li>可以对中间步 (y_k) 也施加监督，让 TRM 学会“怎么一步步纠偏”。</li></ul></li><li><p>指标：</p><ul><li>任务成功率（成功完成抓取 /导航/整理）；</li><li>动作平滑度、越界率；</li><li>运行时延迟 vs baseline。</li></ul></li></ul><hr><h2 id="_5-可能存在的问题-风险讨论" tabindex="-1">5. 可能存在的问题 &amp; 风险讨论 <a class="header-anchor" href="#_5-可能存在的问题-风险讨论" aria-label="Permalink to &quot;5. 可能存在的问题 &amp; 风险讨论&quot;">​</a></h2><p><strong>Slide 11：latent 推理 vs CoT</strong></p><ul><li><p><strong>CoT 的优点：</strong></p><ul><li>可解释性好，适合人类阅读与调试。</li></ul></li><li><p><strong>latent 推理的优点：</strong></p><ul><li>直接对“结构化输出”本身优化；</li><li>每步计算成本小，可以多步递归；</li><li>对 VLA 这类连续控制任务，更自然适配。</li></ul></li><li><p><strong>潜在问题：</strong></p><ul><li>latent 空间不可直观解释，debug 不如 CoT 直观；</li><li>需要设计好 latent 维度与映射，否则信息损失或训练难收敛。</li></ul></li><li><p><strong>综合：</strong></p><ul><li>CoT 更像“嘴上推理”，latent TRM 更像“大脑内部算细节”；</li><li>对我们这种**“结果给机器看”**的结构化任务，优先在 latent 里做推理更合适。</li></ul></li></ul><hr><p><strong>Slide 12：为什么要加 TRM 推理头？直接用 LLM 不行吗？</strong></p><ul><li><p>现状：</p><ul><li>LLM 已经很强，但一个模型同时做“理解 + 推理 + 格式控制”，</li><li>对结构化任务稍微提一点点精度，往往要换更大模型或更复杂 prompt。</li></ul></li><li><p>加 TRM 的好处：</p><ul><li><p><strong>职责分离：</strong></p><ul><li>LLM 负责“看懂问题”；</li><li>TRM 专门负责“在固定格式空间里多步修正答案”。</li></ul></li><li><p><strong>效率更高：</strong></p><ul><li>增加的是一个 7M 级小模型 + 多步迭代，比换更大 LLM 省算力；</li></ul></li><li><p><strong>优化更精准：</strong></p><ul><li>可以专门针对 JSON/动作这些指标做训练，不影响 LLM 的通用能力。</li></ul></li></ul></li><li><p>如何证明必要性（实验设计）：</p><ul><li><p>三组对比：</p><ol><li>只用现有 LLM；</li><li>更大 LLM / 更复杂 CoT；</li><li>LLM + TRM 推理头；</li></ol></li><li><p>比较：结构化输出错误率、任务成功率、算力成本。</p></li></ul></li></ul><hr><p><strong>Slide 13：整体风险与应对策略</strong></p><ul><li><p>风险点：</p><ul><li>训练复杂度增加：需要多步展开 + 深监督；</li><li>推理延迟增加：递归步数带来的额外计算；</li><li>与现有系统集成：接口设计、灰度发布与回退。</li></ul></li><li><p>应对策略：</p><ul><li>从小规模原型开始（单一 function call / 单一 VLA 子任务）；</li><li>优先做“Frozen LLM + 只训 TRM”版本；</li><li>控制递归步数在 3~5 步，评估性能-延迟 trade-off；</li><li>保留无 TRM 的原路径，方便 A/B 灰度和紧急回滚。</li></ul></li></ul><hr><h3 id="收尾页-小结与下一步计划-可选" tabindex="-1">收尾页：小结与下一步计划（可选） <a class="header-anchor" href="#收尾页-小结与下一步计划-可选" aria-label="Permalink to &quot;收尾页：小结与下一步计划（可选）&quot;">​</a></h3><p><strong>Slide 14：小结</strong></p><ul><li><p>我们的目标：</p><ul><li>面向 function call &amp; VLA 两类<strong>结构化输出任务</strong>，</li><li>用 TRM 的递归推理机制给现有模型加一层“可训练的纠错与细节优化”。</li></ul></li><li><p>预期收益：</p><ul><li>提升格式合法率、任务成功率与鲁棒性；</li><li>同时保持算力开销可控。</li></ul></li></ul><p><strong>Slide 15：下一步计划</strong></p><ul><li><p>短期（1–2 个月）：</p><ul><li>完成 function call 场景的 TRM 原型实现与评估；</li><li>对比只 LLM / 大 LLM / LLM+TRM 三种方案。</li></ul></li><li><p>中期（3–6 个月）：</p><ul><li>将 TRM 扩展到 1~2 个关键 VLA 子任务；</li><li>探索 latent 推理与 flow-matching、视频 VLM 的更紧密结合。</li></ul></li><li><p>长期：</p><ul><li>将 “LLM + TRM 推理头” 打造成我们内部的通用结构化输出解决方案，</li><li>在更多机器人与 API 场景中复用。</li></ul></li></ul>',58)])])}const d=i(u,[["render",r]]);export{M as __pageData,d as default};
