import{_ as e,c as t,o as l,ag as o}from"./chunks/framework.CQuhCYrb.js";const p=JSON.parse('{"title":"0901实验分析","description":"","frontmatter":{"title":"0901实验分析","created":"2025-09-07 16:57","updated":"2025-09-07T00:00:00.000Z","origin":"week-36","type":"experiment","status":"draft","tags":[],"links":[]},"headers":[],"relativePath":"40-experiments/250902-0735-0901实验分析.md","filePath":"40-experiments/250902-0735-0901实验分析.md"}'),i={name:"40-experiments/250902-0735-0901实验分析.md"};function r(n,a,s,h,d,c){return l(),t("div",null,[...a[0]||(a[0]=[o('<h2 id="exp-config-meta-把下块注释贴进你的配置文件顶部" tabindex="-1">EXP CONFIG META（把下块注释贴进你的配置文件顶部） <a class="header-anchor" href="#exp-config-meta-把下块注释贴进你的配置文件顶部" aria-label="Permalink to &quot;EXP CONFIG META（把下块注释贴进你的配置文件顶部）&quot;">​</a></h2><h1 id="" tabindex="-1">====================================================================== <a class="header-anchor" href="#" aria-label="Permalink to &quot;======================================================================&quot;">​</a></h1><h1 id="exp-config-meta-paste-at-top-of-your-yaml-toml-ini-config-file" tabindex="-1">EXP CONFIG META (paste at top of your .yaml / .toml / .ini config file) <a class="header-anchor" href="#exp-config-meta-paste-at-top-of-your-yaml-toml-ini-config-file" aria-label="Permalink to &quot;EXP CONFIG META (paste at top of your .yaml / .toml / .ini config file)&quot;">​</a></h1><h1 id="-1" tabindex="-1">---------------------------------------------------------------------- <a class="header-anchor" href="#-1" aria-label="Permalink to &quot;----------------------------------------------------------------------&quot;">​</a></h1><h1 id="exp-id-lt-exp-yyyymmdd-x-e-g-exp-20250903-a" tabindex="-1">EXP_ID : &lt;exp_yyyymmdd_x&gt; # e.g., exp_20250903_A <a class="header-anchor" href="#exp-id-lt-exp-yyyymmdd-x-e-g-exp-20250903-a" aria-label="Permalink to &quot;EXP_ID      : &amp;lt;exp_yyyymmdd_x&gt;          # e.g., exp_20250903_A&quot;">​</a></h1><h1 id="title-lt-short-one-liner-e-g-5l-transencoder-metaquery-256-no-decouple-lr×5" tabindex="-1">TITLE : &lt;short one-liner&gt; # e.g., 5L transencoder, metaquery=256(no-decouple), LR×5 <a class="header-anchor" href="#title-lt-short-one-liner-e-g-5l-transencoder-metaquery-256-no-decouple-lr×5" aria-label="Permalink to &quot;TITLE       : &amp;lt;short one-liner&gt;         # e.g., 5L transencoder, metaquery=256(no-decouple), LR×5&quot;">​</a></h1><h1 id="purpose-lt-what-this-config-is-testing-ablation" tabindex="-1">PURPOSE : &lt;what this config is testing/ablation&gt; <a class="header-anchor" href="#purpose-lt-what-this-config-is-testing-ablation" aria-label="Permalink to &quot;PURPOSE     : &amp;lt;what this config is testing/ablation&gt;&quot;">​</a></h1><h1 id="key-diffs-lt-the-2–4-knobs-that-distinguish-this-config-from-baseline" tabindex="-1">KEY_DIFFS : &lt;the 2–4 knobs that distinguish this config from baseline&gt; <a class="header-anchor" href="#key-diffs-lt-the-2–4-knobs-that-distinguish-this-config-from-baseline" aria-label="Permalink to &quot;KEY_DIFFS   : &amp;lt;the 2–4 knobs that distinguish this config from baseline&gt;&quot;">​</a></h1><h1 id="dataset-lt-e-g-24m-t2i" tabindex="-1">DATASET : &lt;e.g., 24M t2i&gt; <a class="header-anchor" href="#dataset-lt-e-g-24m-t2i" aria-label="Permalink to &quot;DATASET     : &amp;lt;e.g., 24M t2i&gt;&quot;">​</a></h1><h1 id="hardware-lt-e-g-a100×64" tabindex="-1">HARDWARE : &lt;e.g., A100×64&gt; <a class="header-anchor" href="#hardware-lt-e-g-a100×64" aria-label="Permalink to &quot;HARDWARE    : &amp;lt;e.g., A100×64&gt;&quot;">​</a></h1><h1 id="branch-commit-lt-wyq-dev-abc1234-optional" tabindex="-1">BRANCH/COMMIT: &lt;wyq_dev / abc1234&gt; # optional <a class="header-anchor" href="#branch-commit-lt-wyq-dev-abc1234-optional" aria-label="Permalink to &quot;BRANCH/COMMIT: &amp;lt;wyq_dev / abc1234&gt;      # optional&quot;">​</a></h1><h1 id="core-params-lr-batch-res-seed" tabindex="-1">CORE PARAMS : lr=&lt;...&gt;, batch=&lt;...&gt;, res=&lt;...&gt;, seed=&lt;...&gt; <a class="header-anchor" href="#core-params-lr-batch-res-seed" aria-label="Permalink to &quot;CORE PARAMS : lr=&lt;...&gt;, batch=&lt;...&gt;, res=&lt;...&gt;, seed=&lt;...&gt;&quot;">​</a></h1><h1 id="tags-lt-ablation-lt-lrx5-5l-lt-no-decouple-optional" tabindex="-1">TAGS : [&lt;ablation&gt;, &lt;lrx5&gt;, &lt;5L&gt;, &lt;no-decouple&gt;] # optional <a class="header-anchor" href="#tags-lt-ablation-lt-lrx5-5l-lt-no-decouple-optional" aria-label="Permalink to &quot;TAGS        : [&amp;lt;ablation&gt;, &amp;lt;lrx5&gt;, &lt;5L&gt;, &amp;lt;no-decouple&gt;]   # optional&quot;">​</a></h1><h1 id="notes-lt-any-caveat-e-g-warmup↑-grad-clip-needed-etc" tabindex="-1">NOTES : &lt;any caveat, e.g., warmup↑, grad_clip needed, etc.&gt; <a class="header-anchor" href="#notes-lt-any-caveat-e-g-warmup↑-grad-clip-needed-etc" aria-label="Permalink to &quot;NOTES       : &amp;lt;any caveat, e.g., warmup↑, grad_clip needed, etc.&gt;&quot;">​</a></h1><h1 id="-2" tabindex="-1">====================================================================== <a class="header-anchor" href="#-2" aria-label="Permalink to &quot;======================================================================&quot;">​</a></h1><h2 id="目标" tabindex="-1">目标 <a class="header-anchor" href="#目标" aria-label="Permalink to &quot;目标&quot;">​</a></h2><ul><li></li></ul><h2 id="设置-与基线的差异" tabindex="-1">设置（与基线的差异） <a class="header-anchor" href="#设置-与基线的差异" aria-label="Permalink to &quot;设置（与基线的差异）&quot;">​</a></h2><ul><li>数据/分辨率/学习率/权重 等关键改动（≤4 条）</li></ul><h2 id="指标与记录-训练-推理" tabindex="-1">指标与记录（训练/推理） <a class="header-anchor" href="#指标与记录-训练-推理" aria-label="Permalink to &quot;指标与记录（训练/推理）&quot;">​</a></h2><ul><li>&lt;iters&gt; / &lt;metric: value&gt;</li><li>&lt;样例路径或截图&gt;</li></ul><h2 id="结论" tabindex="-1">结论 <a class="header-anchor" href="#结论" aria-label="Permalink to &quot;结论&quot;">​</a></h2><ul><li>&lt;保留/否决/待复验&gt;</li></ul><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to &quot;下一步&quot;">​</a></h2><ul><li></li></ul><h2 id="raw-notes" tabindex="-1">Raw Notes <a class="header-anchor" href="#raw-notes" aria-label="Permalink to &quot;Raw Notes&quot;">​</a></h2><h1 id="今日结果" tabindex="-1">今日结果： <a class="header-anchor" href="#今日结果" aria-label="Permalink to &quot;今日结果：&quot;">​</a></h1><ul><li><p>iteration 40000；</p></li><li><p>0901loss曲线，<img src="https://github.com/user-attachments/assets/e15f7b7d-8314-484f-984e-1946f31fd457" alt="230f6c3a35777cfb8eebe89ba7211846"></p></li><li><p>推理例图（马赛克色块），<img src="https://github.com/user-attachments/assets/7f57632b-96a4-4977-b5c8-82cafed3e51f" alt="b4b7f7d152e49490a3850c35e442b570"> <img src="https://github.com/user-attachments/assets/51f67f60-d0f9-449a-b7e7-e3731b2e7474" alt="a02611c01de843a541ba78b4330e7a6c"></p></li><li><p>总损失稳定在 ~0.98–1.0；拆分：loss_flow ≈ 0.92–0.93，loss_kl ≈ 0.069（kl_raw ≈ 70）。</p></li><li><p>实际 lr 只有 2.5e-7（base_lr=2.5e-6），显著偏低，进入“慢性平台期”区间。</p></li><li><p>模态范数几乎对齐：||z_text||_2 ≈ 70，||x1||_2 ≈ 71，比值 0.98～0.99。</p></li><li><p>z_text 的统计：mu ∈ [-1.15, 1.28]，log_var ∈ [-0.44, 0.02]，即 var≈0.65–1.02，KL 很小 → 后验已接近 N(0,1)。</p></li><li><p>投影链路是“池化→MLP 3层→mu/log_var”，只有全局 pooled feature (||·||≈17) 参与，缺少空间先验。</p></li></ul><hr><h2 id="结论-主要是学习率过低-空间结构缺失-导致-flow-分量难下降-模型会学到颜色统计但画不出形状-。" tabindex="-1">结论： 主要是学习率过低 + 空间结构缺失 导致 flow 分量难下降（模型会学到颜色统计但画不出形状）。 <a class="header-anchor" href="#结论-主要是学习率过低-空间结构缺失-导致-flow-分量难下降-模型会学到颜色统计但画不出形状-。" aria-label="Permalink to &quot;结论： 主要是学习率过低 + 空间结构缺失 导致 flow 分量难下降（模型会学到颜色统计但画不出形状）。&quot;">​</a></h2><hr><h2 id="分析" tabindex="-1">分析 <a class="header-anchor" href="#分析" aria-label="Permalink to &quot;分析&quot;">​</a></h2><ol><li>曲线在告诉我们什么</li></ol><ul><li><p>总 loss ≈ 1.0 长时间平台，KL 在 0.07–0.10 之间缓慢下降： 说明 FM 分量主导，而 KL 约束较弱；模型已经学到颜色统计但全局结构没起势（你前面可视化的马赛克感对应这一点）。</p></li><li><p>LR 调度：base-lr 先升到 ~1e-5 后做长尾衰减，实际 lr（蓝线）只有 ~1–1.5e-6 量级并持续下降。 在大 batch（你之前提到过 40k+ steps）下，这个 有效学习率偏小，加上持续衰减，很容易早早进入“慢磨损”平台期。</p></li></ul><h2 id="立刻可做-按优先级" tabindex="-1">立刻可做（按优先级） <a class="header-anchor" href="#立刻可做-按优先级" aria-label="Permalink to &quot;立刻可做（按优先级）&quot;">​</a></h2><h3 id="_1-重启学习率-最可能立竿见影" tabindex="-1">1) 重启学习率（最可能立竿见影） <a class="header-anchor" href="#_1-重启学习率-最可能立竿见影" aria-label="Permalink to &quot;1) 重启学习率（最可能立竿见影）&quot;">​</a></h3><ul><li>把当前 lr 当作 eta_min做一次 CosineWarmRestarts： <ul><li>for g in optimizer.param_groups: g[&#39;lr&#39;] = 2 * base_lr（比如从 2.5e-6 提到 5e-6；文本/CLIP头≤2e-4，FM主干≤1e-4）</li><li>T0 = 20k, T_mult=1, eta_min = 2.5e-7</li></ul></li><li>目标：让 loss_flow 出现再次下滑（3–5k iters 就能看出趋势）。</li></ul><h3 id="_2-改-t-logsnr-采样-把注意力拉向-中高snr结构段" tabindex="-1">2) 改 t/LogSNR 采样（把注意力拉向“中高SNR结构段”） <a class="header-anchor" href="#_2-改-t-logsnr-采样-把注意力拉向-中高snr结构段" aria-label="Permalink to &quot;2) 改 t/LogSNR 采样（把注意力拉向“中高SNR结构段”）&quot;">​</a></h3><ul><li>你现在是 log_snr = 4 - 8t（t∼U[0,1]）。改为 logSNR 均匀采样：log_snr ∼ U[-2, +6]，或 alpha∈[0.6,0.98]；</li><li>前 30k 步做 curriculum：偏向 alpha&gt;0.8，先把结构学起来，再放宽。</li></ul><h3 id="_3-增强语义-结构监督" tabindex="-1">3) 增强语义/结构监督 <a class="header-anchor" href="#_3-增强语义-结构监督" aria-label="Permalink to &quot;3) 增强语义/结构监督&quot;">​</a></h3><ul><li>CLIP/对比损失权重 ×2（例如 1.0→2.0）；可临时加 LPIPS/VGG 0.1–0.2（前 50k 步）帮助全局结构成形。</li><li>观测：样张应从“噪纹”→“有连续边缘/块”的油画感。</li></ul><h2 id="你这条链路的结构性短板-建议一并修" tabindex="-1">你这条链路的结构性短板（建议一并修） <a class="header-anchor" href="#你这条链路的结构性短板-建议一并修" aria-label="Permalink to &quot;你这条链路的结构性短板（建议一并修）&quot;">​</a></h2><p>当前是 “池化→MLP 输出 8192 维→(mu, log_var)→采样 z_text”。这会让 z_text 缺少二维空间先验，很容易只拟合颜色统计，难以形成局部连贯的结构——与你的样张高度吻合。</p><p>给两个“最小改动”的选项（不推翻大框架）：</p><h3 id="a-网格查询-交叉注意力-推荐" tabindex="-1">A. 网格查询 + 交叉注意力（推荐） <a class="header-anchor" href="#a-网格查询-交叉注意力-推荐" aria-label="Permalink to &quot;A. 网格查询 + 交叉注意力（推荐）&quot;">​</a></h3><ul><li><p>用一个 16×16 learnable query grid（或与 VAE latent 的 H×W 一致），</p></li><li><p>对 q_tokens 做 cross-attn，得到 每个 cell 的特征；</p></li><li><p>对每个 cell 预测 (mu, log_var)，得到 (H,W,C) 的 z_text；</p></li><li><p>在 z_text 上加 2D 位置编码 或 1–2 层 (DW)Conv 3×3，再喂给 flow。</p></li></ul><blockquote><p>这样无需改 VAE/flow 接口，就能给出局部连续性。通常几千步内就能看到结构改善。</p></blockquote><h3 id="b-mlp→-c-h-w-→轻量卷积注入局部性" tabindex="-1">B. “MLP→(C,H,W)→轻量卷积注入局部性” <a class="header-anchor" href="#b-mlp→-c-h-w-→轻量卷积注入局部性" aria-label="Permalink to &quot;B. “MLP→(C,H,W)→轻量卷积注入局部性”&quot;">​</a></h3><ul><li><p>仍然从 pooled feature 经 MLP 得到 8192，reshape 成 (C,H,W)；</p></li><li><p>叠加 几层 3×3 Conv（可 DWConv） + GN/LayerNorm，输出 (mu, log_var)；</p></li><li><p>再采样 z_text 做 flow</p></li></ul><blockquote><p>这是最少代码改动的版本，也能显著缓解“碎片化”。</p></blockquote><p>此外，给 z_text 加一个很小的 <strong>TV 正则（1e-6～5e-6）</strong>，鼓励局部平滑。</p><hr><h1 id="必做健康检查-尽快跑一下" tabindex="-1">必做健康检查（尽快跑一下） <a class="header-anchor" href="#必做健康检查-尽快跑一下" aria-label="Permalink to &quot;必做健康检查（尽快跑一下）&quot;">​</a></h1><ul><li><strong>小批过拟合</strong>：取 512 样本，LR×2，看 2–3k 步是否能把 <code>loss_flow</code> 明显压低（&gt;20%）。压不下 → 实现或数据有问题。</li><li><strong>VAE 一致性</strong>：训练与评估都使用 <code>encode_moments + sample</code>（重参数化），确保 latent <strong>逐通道标准化</strong>一致。</li><li><strong>日志细化</strong>：分别记录 <code>loss_flow/clip/kl</code> 的 EMA 曲线；若仅 <code>flow</code> 卡住，优先调 1) 和 2)。</li><li><strong>amp/梯度</strong>：开 <code>grad_clip=1.0</code>；观察 grad-scale 是否频繁回退。</li><li><strong>增广</strong>：先关强增广，避免把结构监督冲淡。</li></ul><hr><h1 id="建议的权重与调度-可直接套" tabindex="-1">建议的权重与调度（可直接套） <a class="header-anchor" href="#建议的权重与调度-可直接套" aria-label="Permalink to &quot;建议的权重与调度（可直接套）&quot;">​</a></h1><ul><li><code>w_fm=1.0, w_clip=2.0, w_lpips=0.1(前50k), β_KL: 0→0.1 线性 30–50k</code></li><li>Optim：<code>AdamW(betas=0.9,0.95, wd=0.01)</code></li><li>Sched：<strong>CosineWarmRestarts</strong>（见上），并给生成主干加 <strong>EMA=0.999</strong>（训练看非 EMA，推理用 EMA）。</li></ul><hr><p>如果你愿意，我可以给你：</p><ol><li><strong>A/B/C 三路实验的 mmengine 配置段</strong>（LR 重启 / logSNR 采样 / 结构监督增强），</li><li><strong>一个“网格查询 + cross-attn 的最小实现”</strong>（几十行，把 pooled→MLP 换掉），</li><li><strong>TV 正则的一行 Patch</strong>。</li></ol><p>你先按“LR 重启 + logSNR 改采样”做一个 3–5k 步的小试，看看 <code>loss_flow</code> 是否重新下滑、样张是否出现可辨边缘；若有效，再上“空间化头”。</p>',61)])])}const g=e(i,[["render",r]]);export{p as __pageData,g as default};
