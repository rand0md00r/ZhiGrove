import{_ as e,c as r,o as n,ag as o}from"./chunks/framework.OaOo95RB.js";const u=JSON.parse('{"title":"===================================================================================","description":"","frontmatter":{},"headers":[],"relativePath":"40-experiments/exp_card_0908_dinov2.md","filePath":"40-experiments/exp_card_0908_dinov2.md"}'),t={name:"40-experiments/exp_card_0908_dinov2.md"};function l(i,a,s,d,h,c){return n(),r("div",null,[...a[0]||(a[0]=[o('<h1 id="" tabindex="-1">=================================================================================== <a class="header-anchor" href="#" aria-label="Permalink to &quot;===================================================================================&quot;">​</a></h1><h1 id="实验配置-internvl-query-5transencoder-sdvae-23m-256pix-bs4096-0903-py" tabindex="-1">实验配置：internvl_query_5TransEncoder_sdvae_23m_256pix_bs4096_0903.py <a class="header-anchor" href="#实验配置-internvl-query-5transencoder-sdvae-23m-256pix-bs4096-0903-py" aria-label="Permalink to &quot;实验配置：internvl_query_5TransEncoder_sdvae_23m_256pix_bs4096_0903.py&quot;">​</a></h1><h1 id="-1" tabindex="-1">----------------------------------------------------------------------------------- <a class="header-anchor" href="#-1" aria-label="Permalink to &quot;-----------------------------------------------------------------------------------&quot;">​</a></h1><h1 id="internvl3-query-5transencoder-sdvae-23m-配置" tabindex="-1">InternVL3 Query 5TransEncoder SDVAE 23M 配置 <a class="header-anchor" href="#internvl3-query-5transencoder-sdvae-23m-配置" aria-label="Permalink to &quot;InternVL3 Query 5TransEncoder SDVAE 23M 配置&quot;">​</a></h1><h1 id="-2" tabindex="-1"><a class="header-anchor" href="#-2" aria-label="Permalink to &quot;&quot;">​</a></h1><h1 id="基础配置" tabindex="-1">基础配置： <a class="header-anchor" href="#基础配置" aria-label="Permalink to &quot;基础配置：&quot;">​</a></h1><h1 id="本配置用于训练-internvl3-query-crossflow-架构-采用-0-层-transencoder-作为文本特征压缩器" tabindex="-1">本配置用于训练 InternVL3-Query-CrossFlow 架构，采用 0 层 TransEncoder 作为文本特征压缩器， <a class="header-anchor" href="#本配置用于训练-internvl3-query-crossflow-架构-采用-0-层-transencoder-作为文本特征压缩器" aria-label="Permalink to &quot;本配置用于训练 InternVL3-Query-CrossFlow 架构，采用 0 层 TransEncoder 作为文本特征压缩器，&quot;">​</a></h1><h1 id="搭配-sdvae-23m-图像自编码器-输入分辨率为-256-像素-批量大小-4096。" tabindex="-1">搭配 SDVAE 23M 图像自编码器，输入分辨率为 256 像素，批量大小 4096。 <a class="header-anchor" href="#搭配-sdvae-23m-图像自编码器-输入分辨率为-256-像素-批量大小-4096。" aria-label="Permalink to &quot;搭配 SDVAE 23M 图像自编码器，输入分辨率为 256 像素，批量大小 4096。&quot;">​</a></h1><h1 id="llm-backbone-internvl3-2b" tabindex="-1">- LLM Backbone: InternVL3-2B <a class="header-anchor" href="#llm-backbone-internvl3-2b" aria-label="Permalink to &quot;- LLM Backbone: InternVL3-2B&quot;">​</a></h1><h1 id="图像自编码器-dc-ae-f32c32-sana-1-1-diffusers" tabindex="-1">- 图像自编码器: dc-ae-f32c32-sana-1.1-diffusers <a class="header-anchor" href="#图像自编码器-dc-ae-f32c32-sana-1-1-diffusers" aria-label="Permalink to &quot;- 图像自编码器: dc-ae-f32c32-sana-1.1-diffusers&quot;">​</a></h1><h1 id="图像分辨率-256x256" tabindex="-1">- 图像分辨率: 256x256 <a class="header-anchor" href="#图像分辨率-256x256" aria-label="Permalink to &quot;- 图像分辨率: 256x256&quot;">​</a></h1><h1 id="批量大小-4096" tabindex="-1">- 批量大小: 4096 <a class="header-anchor" href="#批量大小-4096" aria-label="Permalink to &quot;- 批量大小: 4096&quot;">​</a></h1><h1 id="支持多种损失与训练策略-包括flow-matching、kl-正则、dino-v2" tabindex="-1">- 支持多种损失与训练策略（包括Flow Matching、KL 正则、DINO v2） <a class="header-anchor" href="#支持多种损失与训练策略-包括flow-matching、kl-正则、dino-v2" aria-label="Permalink to &quot;- 支持多种损失与训练策略（包括Flow Matching、KL 正则、DINO v2）&quot;">​</a></h1><h1 id="适配-deepspeed-分布式训练" tabindex="-1">- 适配 deepspeed 分布式训练 <a class="header-anchor" href="#适配-deepspeed-分布式训练" aria-label="Permalink to &quot;- 适配 deepspeed 分布式训练&quot;">​</a></h1><h1 id="-3" tabindex="-1"><a class="header-anchor" href="#-3" aria-label="Permalink to &quot;&quot;">​</a></h1><h1 id="实验参数" tabindex="-1">实验参数： <a class="header-anchor" href="#实验参数" aria-label="Permalink to &quot;实验参数：&quot;">​</a></h1><h1 id="文本编码器-0-层-transencoder-3层-reductionlayer" tabindex="-1">- 文本编码器: 0 层 TransEncoder，3层 ReductionLayer <a class="header-anchor" href="#文本编码器-0-层-transencoder-3层-reductionlayer" aria-label="Permalink to &quot;- 文本编码器: 0 层 TransEncoder，3层 ReductionLayer&quot;">​</a></h1><h1 id="lr-5e-5" tabindex="-1">- LR : 5e-5 <a class="header-anchor" href="#lr-5e-5" aria-label="Permalink to &quot;- LR : 5e-5&quot;">​</a></h1><h1 id="batch-size-64" tabindex="-1">- batch size = 64 <a class="header-anchor" href="#batch-size-64" aria-label="Permalink to &quot;- batch size = 64&quot;">​</a></h1><h1 id="global-batch-4096" tabindex="-1">- global batch = 4096 <a class="header-anchor" href="#global-batch-4096" aria-label="Permalink to &quot;- global batch = 4096&quot;">​</a></h1><h1 id="max-iterations-120000-20-epochs" tabindex="-1">- max_iterations: 120000(20 epochs) <a class="header-anchor" href="#max-iterations-120000-20-epochs" aria-label="Permalink to &quot;- max_iterations: 120000(20 epochs)&quot;">​</a></h1><h1 id="dino-v2-loss-only-global" tabindex="-1">- DINO v2 loss (only global) <a class="header-anchor" href="#dino-v2-loss-only-global" aria-label="Permalink to &quot;- DINO v2 loss (only global)&quot;">​</a></h1><h1 id="-4" tabindex="-1"><a class="header-anchor" href="#-4" aria-label="Permalink to &quot;&quot;">​</a></h1><h1 id="-5" tabindex="-1">=================================================================================== <a class="header-anchor" href="#-5" aria-label="Permalink to &quot;===================================================================================&quot;">​</a></h1>',24)])])}const q=e(t,[["render",l]]);export{u as __pageData,q as default};
