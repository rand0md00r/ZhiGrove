import{_ as l,c as e,o as i,ag as t}from"./chunks/framework.OaOo95RB.js";const _=JSON.parse('{"title":"idea 汇总 20205年9月7日 18:36","description":"","frontmatter":{},"headers":[],"relativePath":"30-ideas/2025/9月/week36-论文实验idea汇总.md","filePath":"30-ideas/2025/9月/week36-论文实验idea汇总.md"}'),o={name:"30-ideas/2025/9月/week36-论文实验idea汇总.md"};function r(d,a,s,n,u,h){return i(),e("div",null,[...a[0]||(a[0]=[t('<h1 id="idea-汇总-20205年9月7日-18-36" tabindex="-1">idea 汇总 20205年9月7日 18:36 <a class="header-anchor" href="#idea-汇总-20205年9月7日-18-36" aria-label="Permalink to &quot;idea 汇总 20205年9月7日 18:36&quot;">​</a></h1><h2 id="待实践方案" tabindex="-1">待实践方案： <a class="header-anchor" href="#待实践方案" aria-label="Permalink to &quot;待实践方案：&quot;">​</a></h2><h3 id="分块稀疏query-moe-传输" tabindex="-1">分块稀疏Query + MoE 传输 <a class="header-anchor" href="#分块稀疏query-moe-传输" aria-label="Permalink to &quot;分块稀疏Query + MoE 传输&quot;">​</a></h3><ul><li><p>source： 30-ideas/[250829-0735]中间层模型方案梳理.md</p></li><li><p>方案描述：</p><ul><li>分块稀疏Query，将vl query作为前缀，输入到一个MoE llama里，连接到高斯空间；</li><li>实验进展：未验证；</li></ul></li><li><p>坑：分块重排方案可能导致特征混乱；</p></li></ul><h3 id="语义监督方案" tabindex="-1">语义监督方案： <a class="header-anchor" href="#语义监督方案" aria-label="Permalink to &quot;语义监督方案：&quot;">​</a></h3><ul><li>source：30-ideas/[250827-0736]0826-与弘扬沟通.md</li></ul><ol><li>VICReg + dino v2</li></ol><ul><li>特点：无负样本的表示学习——用“不变性 + 方差约束 + 协方差去相关”避免坍塌、提升表征质量。</li><li>deno v2</li></ul><ol start="2"><li>siglip</li></ol><ul><li>特点：把图文匹配当 独立二分类（BCE with logits）——“每一对都是一个 0/1 判断”。</li></ul><ol start="3"><li>使用VAE latent做语义监督标签</li></ol><ul><li>为什么CrossFlow没有使用label做对比损失？</li></ul><blockquote><p>因为 VAE 的图像 latent 不具备良好的“语义几何”，而 CLIP 空间天生是语义对齐的。CrossFlow 需要把“文本分布 → 图像分布”的流匹配学好，就得先把文本侧编码进一个语义结构良好、与图像语义一致的空间来当源分布锚点；直接在 VAE 图像 latent 上做（按 label 的）对比/重构，语义信号弱，效果差。 - 1. 重构≠语义：作者直接试过用 VAE 式的重构损失训练 Text-VE，重构误差虽然低，但“语义概念捕获得不好，生成效果变差”；改用对比损失（CLIP 风格）显著更好，其中文本-图像对比又略优于文本-文本对比。论文在 §4.4.1 与消融里明确给出这一点。 - 2. 空间几何不匹配：图像 VAE latent（如 4×H×W）更多承载低层像素与风格信息，分布各向异性强、量纲复杂；把它拿来按类别/标签做对比，会把同类样本捏得过近、与实例级语义错位，还可能伤到生成质量。CLIP 空间则是单位归一化、接近各向同性、与自然语言实例级对齐的嵌入，做 InfoNCE/BCE 更稳定。 - 3.</p></blockquote><h2 id="其他方向idea-暂不实践" tabindex="-1">其他方向idea（暂不实践）： <a class="header-anchor" href="#其他方向idea-暂不实践" aria-label="Permalink to &quot;其他方向idea（暂不实践）：&quot;">​</a></h2><ol><li>超长视频理解，做时空建模记忆实现。 理解单个图片 -&gt; 理解短视频 -&gt; 理解流式视频 -&gt; 持续action；</li><li>后面我们还可以做多轮对话那种 存储metaquery的KV矩阵做矩阵 然后利用ODE的可逆性 这个可能也是后面能拓展的一点</li><li></li></ol><h2 id="验证不行的方案" tabindex="-1">验证不行的方案： <a class="header-anchor" href="#验证不行的方案" aria-label="Permalink to &quot;验证不行的方案：&quot;">​</a></h2><ol><li>clip语义监督</li></ol><ul><li>特点：基于 InfoNCE 的行/列 softmax 对比学习——“从一堆候选里选对的那个”。</li><li>多模态输入无法处理（但是当前为纯文本输出，为什么也不行？）</li></ul>',18)])])}const m=l(o,[["render",r]]);export{_ as __pageData,m as default};
