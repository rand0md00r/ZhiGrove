import{_ as i,c as a,o as n,ag as t}from"./chunks/framework.CQuhCYrb.js";const o=JSON.parse('{"title":"是什么（核心思想）","description":"","frontmatter":{},"headers":[],"relativePath":"00-inbox/week-37/250908-0020-siglip损失.md","filePath":"00-inbox/week-37/250908-0020-siglip损失.md"}'),l={name:"00-inbox/week-37/250908-0020-siglip损失.md"};function h(p,s,k,e,r,g){return n(),a("div",null,[...s[0]||(s[0]=[t(`<p>下面把 <strong>SigLIP 损失</strong>（Sigmoid Loss for Language-Image Pretraining）用最精简的方式讲清楚：</p><h1 id="是什么-核心思想" tabindex="-1">是什么（核心思想） <a class="header-anchor" href="#是什么-核心思想" aria-label="Permalink to &quot;是什么（核心思想）&quot;">​</a></h1><p>把“图-文是否匹配”看成<strong>二元分类</strong>。对一个 batch 的所有图文两两组合都做判别：匹配对为 1，不匹配为 0，用 <strong>sigmoid + 二元交叉熵（BCE）</strong> 优化，而不是像 CLIP 那样用 softmax 的 InfoNCE。</p><h1 id="数学定义-最小公式" tabindex="-1">数学定义（最小公式） <a class="header-anchor" href="#数学定义-最小公式" aria-label="Permalink to &quot;数学定义（最小公式）&quot;">​</a></h1><p>设已归一化的图像/文本向量分别为 $v_i, t_j$，相似度</p><p>$$ s_{ij} = \\tau \\cdot v_i^\\top t_j $$</p><p>$\\tau&gt;0$ 是可学习温度（或用 $1/T$）。给定标签矩阵 $y_{ij}\\in{0,1}$（匹配对为 1），SigLIP 损失：</p><p>$$ \\mathcal{L} ;=; \\frac{1}{N}\\sum_{i,j}\\Big[, -,y_{ij}\\log\\sigma(s_{ij}) ;-; (1-y_{ij})\\log\\big(1-\\sigma(s_{ij})\\big) \\Big] $$</p><p>实践中常用 <strong>加权 BCE</strong> 缓解“负样本远多于正样本”的不均衡（如对正样本加权 $\\text{pos_weight}\\approx B-1$）。</p><h1 id="和-clip-的关键差异" tabindex="-1">和 CLIP 的关键差异 <a class="header-anchor" href="#和-clip-的关键差异" aria-label="Permalink to &quot;和 CLIP 的关键差异&quot;">​</a></h1><ul><li><strong>目标不同</strong>：CLIP 用行/列 softmax 的 InfoNCE（“选出这行/这列中的正确配对”）；SigLIP 用 <strong>独立二分类</strong>（每个 $s_{ij}$ 都被监督）。</li><li><strong>多正样本更自然</strong>：一图多 caption 或一文多图时，SigLIP 直接把多对 $y_{ij}=1$ 标出来即可；CLIP 需要更繁琐的处理。</li><li><strong>对噪声/弱对齐更鲁棒</strong>：不是“谁最大就对”，而是“每一对都评估置信度”。</li></ul><h1 id="怎么用-落地步骤" tabindex="-1">怎么用（落地步骤） <a class="header-anchor" href="#怎么用-落地步骤" aria-label="Permalink to &quot;怎么用（落地步骤）&quot;">​</a></h1><ol><li><p><strong>取特征并归一化</strong>：<code>v = img_enc(x)/||·||</code>，<code>t = txt_enc(y)/||·||</code>。</p></li><li><p><strong>相似度矩阵</strong>：<code>logits = tau * v @ t.T</code>（$\\tau$ 可学习或固定为 $1/T$）。</p></li><li><p><strong>标签矩阵</strong>：默认对角为 1（同索引为匹配），其余为 0。多正样本时按 id 匹配构造 $y$。</p></li><li><p><strong>损失</strong>：<code>BCEWithLogits(logits, y, pos_weight=...)</code>；或手写 BCE。</p></li><li><p><strong>技巧</strong>：</p><ul><li>学习式 <code>logit_scale</code>（$\\tau$）并裁剪到合理范围（如 $[0, \\ln 100]$）。</li><li>对正样本加权（<code>pos_weight=B-1</code> 是一个常用起点）。</li><li>大 batch / 跨卡 gather 能带来更多难负样本。</li><li>支持 label smoothing / hard-negative 采样可再稳一点。</li></ul></li></ol><h1 id="最小-pytorch-示例" tabindex="-1">最小 PyTorch 示例 <a class="header-anchor" href="#最小-pytorch-示例" aria-label="Permalink to &quot;最小 PyTorch 示例&quot;">​</a></h1><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.functional </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> siglip_loss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(img_emb, txt_emb, img_ids</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, txt_ids</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, logit_scale</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    img_emb: [B, D] normalized</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    txt_emb: [B, D] normalized</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    img_ids/txt_ids: [B]，可选；用于多正样本情形（同 id 视为正例）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    logit_scale: 可学习标量张量或 None（默认取 1/0.07）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> img_emb.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logit_scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        logit_scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.07</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">img_emb.device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logit_scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> img_emb </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> txt_emb.t()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [B, B]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> img_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> txt_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 单正样本：主对角为 1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        targets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.eye(B, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">img_emb.device)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 多正样本：同 id 置为 1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        targets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (img_ids[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> txt_ids[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, :]).float()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 类不平衡：每行仅 ~1 个正样本</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pos_weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.full_like(logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">fill_value</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">B</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 也可用标量：pos_weight_scalar = B - 1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F.binary_cross_entropy_with_logits(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        logits, targets, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pos_weight</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pos_weight</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss</span></span></code></pre></div><h1 id="使用建议-你当前项目里怎么插" tabindex="-1">使用建议（你当前项目里怎么插） <a class="header-anchor" href="#使用建议-你当前项目里怎么插" aria-label="Permalink to &quot;使用建议（你当前项目里怎么插）&quot;">​</a></h1><ul><li><strong>替换 CLIP 损失</strong>：把原来的行/列 InfoNCE 换成上面的 BCE（保持双塔结构不变）。</li><li><strong>多配对数据友好</strong>：若一图多描述，直接把对应 $y_{ij}=1$；不必人为只留一个正样本。</li><li><strong>与 FM/KL 等多目标并行</strong>：SigLIP 输出的对齐梯度通常更平滑，和 flow-matching、VAE KL 一起时，给 SigLIP 一个<strong>中等偏上</strong>的权重，然后用梯度范数监控/自适应调权更稳。</li><li><strong>监控指标</strong>：batch 内 top-k 命中率（row/col recall@k）、对角/非对角 logits 的分布间隔、$\\tau$ 的收敛轨迹。</li></ul><p>如果你愿意，我可以把你现有的 CLIP 对齐模块改成 SigLIP 版本（包括多正样本标签构造与分布式 all-gather 支持）的最小可用代码骨架。</p>`,18)])])}const d=i(l,[["render",h]]);export{o as __pageData,d as default};
