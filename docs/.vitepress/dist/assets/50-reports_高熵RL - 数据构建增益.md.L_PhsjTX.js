import{_ as r,c as n,o,ag as a}from"./chunks/framework.OaOo95RB.js";const u=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"50-reports/高熵RL - 数据构建增益.md","filePath":"50-reports/高熵RL - 数据构建增益.md"}'),e={name:"50-reports/高熵RL - 数据构建增益.md"};function s(i,t,l,p,g,c){return o(),n("div",null,[...t[0]||(t[0]=[a('<h2 id="结论先行" tabindex="-1">结论先行 <a class="header-anchor" href="#结论先行" aria-label="Permalink to &quot;结论先行&quot;">​</a></h2><blockquote><p>可行。通过“发现并放大高熵分岔点”，提前数据构建可以提高RL后训练的<strong>样本效率</strong>、<strong>稳定性</strong>与<strong>最终效果</strong>。</p></blockquote><blockquote><p>基本思路，按RL后训练预期的方式构造批量数据进行SFT，加快收敛速度，稳定训练效果。</p></blockquote><h2 id="方案的简要描述" tabindex="-1">方案的简要描述 <a class="header-anchor" href="#方案的简要描述" aria-label="Permalink to &quot;方案的简要描述&quot;">​</a></h2><h3 id="a-高熵实例挖掘-uncertainty-mining" tabindex="-1">A. 高熵实例挖掘（Uncertainty Mining） <a class="header-anchor" href="#a-高熵实例挖掘-uncertainty-mining" aria-label="Permalink to &quot;A. 高熵实例挖掘（Uncertainty Mining）&quot;">​</a></h3><p><strong>具体做法</strong>：</p><ul><li><p>让现有模型把候选数据“过一遍”，记录每个位置的token 熵（拿不准的程度）。</p></li><li><p>选出高熵位置多、分布分散的样本入库；低熵、机械续写的样本就少用或丢掉。</p></li><li><p>强化学习时，要么只在高熵位置更新（挑批内熵最高的前 10–30% 位置），要么在高熵位置给优势加权（高熵处“多踩油门”）。</p></li></ul><p><strong>特点</strong>：成本最低、与 PPO/GRPO 无缝兼容、训练的收敛更快</p><h3 id="b-边界对比数据-counterfactual-n-best" tabindex="-1">B. 边界对比数据（Counterfactual &amp; n-best） <a class="header-anchor" href="#b-边界对比数据-counterfactual-n-best" aria-label="Permalink to &quot;B. 边界对比数据（Counterfactual &amp; n-best）&quot;">​</a></h3><p><strong>具体做法</strong>：</p><ul><li><p>对同一问题做最小修改（换一个数字/条件/别名），让答案刚好翻转，形成一对“几乎一样但结论相反”的样本。</p></li><li><p>采集每个问题的 n-best 多候选（几条对、几条错），让模型在同一前缀下见到不同走向。</p></li><li><p>这些数据先做轻量 SFT（定格式），再进 GRPO/PPO 或 DPO，训练时重点关注差别发生的关节点。</p></li></ul><p><strong>特点</strong>： - 这类数据把模型直接丢到决策边界上：小改动→大后果，梯度信息最密。</p><h3 id="c-锚点前缀库-局部展开-fr3e-思路" tabindex="-1">C. 锚点前缀库 + 局部展开（FR3E 思路） <a class="header-anchor" href="#c-锚点前缀库-局部展开-fr3e-思路" aria-label="Permalink to &quot;C. 锚点前缀库 + 局部展开（FR3E 思路）&quot;">​</a></h3><p><strong>具体做法</strong>：</p><ul><li>在一条生成里挑出 <strong>Top-K</strong> 个高熵位置当“锚点”，把 <strong>提示 + 到此为止的前缀</strong> 存成“前缀库”。</li><li>训练时从某个锚点<strong>读档</strong>，从这里继续采样 <strong>M 次</strong>到终局，计算“从这个分岔口继续走能走对的平均概率”： [ V(S_j)=\\frac{1}{M}\\sum_{m=1}^{M} r_{j,m} ]</li><li>用“<strong>实际结果 − 平均结果</strong>”当优势更新策略： [ A_{j,m}=r_{j,m}-V(S_j) ] （进步区域<strong>降一点力度</strong>，受阻区域<strong>加一点力度</strong>；其它训练配方不变）</li></ul><p><strong>特点</strong>：把稀疏终局奖“压回中间”，显著改善<strong>信用分配</strong>与<strong>训练稳定性</strong>。</p>',16)])])}const h=r(e,[["render",s]]);export{u as __pageData,h as default};
