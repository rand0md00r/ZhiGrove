import{_ as e,c as t,o as l,ag as i}from"./chunks/framework.OaOo95RB.js";const h=JSON.parse('{"title":"pipeline检查","description":"","frontmatter":{"title":"pipeline检查","created":"2025-09-07 17:02","updated":"2025-09-07T00:00:00.000Z","origin":"week-35","type":"knowledge","status":"draft","tags":["flow-matching","VAE","latent-scaling","KL","training-checklist"],"links":[]},"headers":[],"relativePath":"10-knowledge/250830-0735-pipeline检查-overview.md","filePath":"10-knowledge/250830-0735-pipeline检查-overview.md"}'),s={name:"10-knowledge/250830-0735-pipeline检查-overview.md"};function a(n,o,r,c,d,g){return l(),t("div",null,[...o[0]||(o[0]=[i(`<h2 id="tl-dr-≤3点" tabindex="-1">TL;DR（≤3点） <a class="header-anchor" href="#tl-dr-≤3点" aria-label="Permalink to &quot;TL;DR（≤3点）&quot;">​</a></h2><ul><li><strong>先看尺度</strong>：确保 <code>z₀</code>（文本头部采样）与 <code>z₁</code>（VAE latent）在<strong>同一缩放</strong>与<strong>同一统计量级</strong>（典型 <code>∥z∥₂</code> 批均值同量级，差不超 2–3×）。</li><li><strong>再看目标</strong>：噪声自由 FM 下，路径 <code>x_t=(1-t)x₀+t x₁</code>，目标速度 <strong><code>v* = x₁ - x₀</code>（常数）</strong>；别把 <code>ε</code>/score 目标混进去，别反号。</li><li><strong>防“卡死”</strong>：给 KL <strong>warmup</strong> + 对 <code>logvar</code> 合理 <strong>clamp</strong>；<code>v*</code> 计算时对 <code>x₀,x₁</code> <strong>detach</strong>，只让预测 <code>u_θ</code> 回传。</li></ul><h2 id="what-是什么" tabindex="-1">What（是什么） <a class="header-anchor" href="#what-是什么" aria-label="Permalink to &quot;What（是什么）&quot;">​</a></h2><ul><li>这是一个从「<strong>尺度</strong>、<strong>目标</strong>、<strong>梯度</strong>、<strong>结构</strong>」四个维度快速排障的 <strong>Flow Matching（FM） 文本→图像潜空间</strong>训练检查单。</li><li>你的 pipeline：文本 → VLM → <code>q_token</code> → 线性头（3层）→ <code>(μ, logvar)</code> → <strong>采样</strong> <code>z₀</code> →（noise-free）FM → 目标图像 latent <code>z₁</code>。</li></ul><h2 id="why-为什么这么做-何时使用" tabindex="-1">Why（为什么这么做/何时使用） <a class="header-anchor" href="#why-为什么这么做-何时使用" aria-label="Permalink to &quot;Why（为什么这么做/何时使用）&quot;">​</a></h2><ul><li>FM 在噪声自由设定下对<strong>尺度极敏感</strong>；任何一端的单位或缩放错位都会让 <code>v*=x₁-x₀</code> 被<strong>一侧主导</strong>，训练发散或头部/KL “卡死”。</li><li>目标写错（把 DDPM 的 <code>ε</code> 当目标；或把速度反号）会导致模型学到错误物理量，损失不降。</li><li>KL 与 <code>logvar</code> 容易在早期<strong>过强/过小</strong>，需要暖启动与数值保护。</li></ul><h2 id="how-最小复现配方-≤5步" tabindex="-1">How（最小复现配方，≤5步） <a class="header-anchor" href="#how-最小复现配方-≤5步" aria-label="Permalink to &quot;How（最小复现配方，≤5步）&quot;">​</a></h2><ol><li><strong>对齐 VAE 缩放</strong><br> 核对 autoencoder 的 <code>scaling_factor</code>（SD 家族常见 <strong>0.18215</strong>；也有其他值）。确保： <ul><li><code>encode()</code> / <code>encode_moments()</code> 返回的量<strong>是否已乘</strong>缩放；</li><li>你的 <code>z₁</code> 与解码 <code>decode()</code> 的接口<strong>互逆</strong>（编码乘、解码除，或反之，切勿重复/漏乘）。</li></ul></li><li><strong>量纲自检</strong><br> 同一批次打印 <ul><li><code>E[∥z₀∥₂]</code>, <code>E[∥z₁∥₂]</code>, <code>E[∥x_t∥₂]</code>（t~U[0,1]）、<code>E[∥v*∥₂]</code>；</li><li>期望它们同量级；若 <code>z₁</code> 比 <code>z₀</code> 大 <strong>&gt;3×</strong>，优先修正缩放而非引入额外比值校正。</li></ul></li><li><strong>目标定义核对（noise-free FM）</strong><ul><li>路径：<code>x_t=(1-t)x₀+t x₁</code>；目标：<code>v*(x_t,t)=x₁-x₀</code>（与 t 无关）。</li><li>训练：最小化 <code>E_{t,x₀,x₁} [‖u_θ(x_t, t, cond) - (x₁ - x₀)‖²]</code>。</li><li><strong>注意</strong>：<code>x₀, x₁</code> 在构造 <code>v*</code> 时 <strong>detach</strong>，防止“移动靶”。</li></ul></li><li><strong>KL 稳定化</strong><ul><li>令 <code>q_φ(z₀|text)=N(μ, diag(σ²))</code>，对 <code>KL(q_φ‖N(0,I))</code> 做 <strong>warmup</strong>（如前 10% 训练从 0 线性升至目标权重）。</li><li>对 <code>logvar=log σ²</code> <strong>clamp 到 [-6,6]</strong>（或依据数据调），避免早期 σ→0 导致 KL 爆大。</li></ul></li><li><strong>小集合过拟合</strong><ul><li>固定一小撮（如 128 条）样本，观察<strong>数小时内</strong>：FM MSE 下降、<code>cos(u_θ, v*)↑</code>、KL 平稳；若不能过拟合，回到 1–4 排查。</li></ul></li></ol><h2 id="gotchas-坑点与边界" tabindex="-1">Gotchas（坑点与边界） <a class="header-anchor" href="#gotchas-坑点与边界" aria-label="Permalink to &quot;Gotchas（坑点与边界）&quot;">​</a></h2><ul><li><strong>尺度优先</strong>：别用临时比值 <code>r=∥z₁∥/∥z₀∥</code> 去“救火”，先把 VAE 的缩放口径搞对。</li><li><strong>目标不混淆</strong>：FM 的速度目标 <code>x₁-x₀</code> ≠ DDPM 的噪声 <code>ε</code>，也 ≠ score；签名错/混合会让损失表面看降实则学偏。</li><li><strong>时间编码</strong>：若给 <code>t</code> 做正弦位置编码/MLP，<strong>注意幅值</strong>（过大易主导网络），可做 LayerNorm 或小幅度初始化。</li><li><strong>损失归一化</strong>：MSE/维度平均要与 KL 权重在<strong>同一数量级</strong>；记录两者量纲，避免某项“淹没”另一项。</li><li><strong>梯度路径</strong>：<code>z₀</code> 由 reparam 采样得到，<strong>允许</strong>梯度回到 <code>(μ, logvar)</code>（经 reparam trick），但<strong>不允许</strong>通过 <code>v*</code> 反向“改目标”（对 <code>x₀,x₁</code> detach）。</li><li><strong>数值精度</strong>：半精度下启用 GradScaler / 动态 loss scaling；<code>x_t</code> 的构造尽量 FP32 计算后再 cast。</li><li><strong>数据口径</strong>：文本与图像对齐、增广一致性、VAE 的 train/eval 模式（某些 VAE 在 eval 关闭噪声/BN）。</li><li><strong>评估口径</strong>：仅在<strong>相同</strong> VAE、分辨率、latent 维度、缩放下比较指标；跨口径比较没有意义。</li></ul><h2 id="raw-notes" tabindex="-1">Raw Notes <a class="header-anchor" href="#raw-notes" aria-label="Permalink to &quot;Raw Notes&quot;">​</a></h2><p>从「尺度、目标、梯度、结构」四类问题排</p><p>现在的pipeline是：</p><ul><li>文本 → VLM → q_token → 三层 Linear → (μ, logvar) → 采样 z₀ →（noise-free）Flow Matching → 目标图像潜变量 z₁</li></ul><h1 id="to-check-list" tabindex="-1">To check list <a class="header-anchor" href="#to-check-list" aria-label="Permalink to &quot;To check list&quot;">​</a></h1><ul><li><ol><li>VAE 潜空间尺度对齐（最容易踩坑）</li></ol></li></ul><p>SD/VAEs 往往用 scale=0.18215。确保 z₁ 和你头部输出的 z₀ 在同一量纲。</p><ul><li><p>若 encode() 已返回规范化 latent，就不要再乘/除；</p></li><li><p>打印 ||z₁||₂ 与 ||z₀||₂ 的 batch 均值：两者差不要超过 2–3 倍。若差距大，先把头部权重缩小或把 z₁ 做相同缩放。</p></li><li><p>问题1：x0和x1的尺度差异过大，∥x0∥≈151~155， ∥x1∥≈896~1224，在 FM 里目标速度 v = x1 - x0 会被 x1 的尺度完全主导，头部和 KL 会“卡死”。</p><ul><li>（不需要）加个 r = (z1.pow(2).mean().sqrt() / (z0.pow(2).mean().sqrt() + 1e-8)).clamp(1e-3, 1e3)</li><li>原因：没有采样：</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mu, logvar </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> autoencoder.encode_moments(x)         </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 只算参数，不采样</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># = posterior = autoencoder.encode(x)              # 某些实现返回分布对象</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   posterior.mean(), posterior.sample()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> autoencoder.sample(x)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 内部：encode_moments -&gt; reparam -&gt; (可能)乘 scaling_factor</span></span></code></pre></div><ul><li>mu, logvar：像素 x 的后验分布参数，单张图是对角高斯N(μ(x),σ2(x)I)</li><li>sample(x)：返回一次采样的潜变量（训练期常用）。</li><li>scaling_factor：很多 LDM/SD 家族把潜空间统一缩放（编码时乘、解码时除）。别重复乘或漏乘，否则会出现你刚看到的“z1 量级巨大”。</li></ul></li><li><ol start="2"><li>KL权重与logvar范围</li></ol><ul><li><p>平台常见因：logvar 一开始太小（σ→0），KL 过强把头部压死。</p></li><li><p>暂时 clamp logvar ∈ [-6, 6]，并 KL warmup（前 10% step 从 0 线性升到目标值）。</p></li></ul></li><li><ol start="3"><li>FLow目标是否正确？</li></ol></li></ul>`,18)])])}const u=e(s,[["render",a]]);export{h as __pageData,u as default};
