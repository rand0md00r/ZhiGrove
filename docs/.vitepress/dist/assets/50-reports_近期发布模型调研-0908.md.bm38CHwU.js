import{_ as r,c as o,o as n,ag as i}from"./chunks/framework.OaOo95RB.js";const d=JSON.parse('{"title":"Qwen3-Max-Preview vs. Kimi K2-0905｜调研简报（2025-09-08）","description":"","frontmatter":{},"headers":[],"relativePath":"50-reports/近期发布模型调研-0908.md","filePath":"50-reports/近期发布模型调研-0908.md"}'),e={name:"50-reports/近期发布模型调研-0908.md"};function s(a,t,l,g,u,h){return n(),o("div",null,[...t[0]||(t[0]=[i('<h1 id="qwen3-max-preview-vs-kimi-k2-0905-调研简报-2025-09-08" tabindex="-1">Qwen3-Max-Preview vs. Kimi K2-0905｜调研简报（2025-09-08） <a class="header-anchor" href="#qwen3-max-preview-vs-kimi-k2-0905-调研简报-2025-09-08" aria-label="Permalink to &quot;Qwen3-Max-Preview vs. Kimi K2-0905｜调研简报（2025-09-08）&quot;">​</a></h1><hr><h2 id="qwen3-max-preview-闭源·预览" tabindex="-1">Qwen3-Max-Preview（闭源·预览） <a class="header-anchor" href="#qwen3-max-preview-闭源·预览" aria-label="Permalink to &quot;Qwen3-Max-Preview（闭源·预览）&quot;">​</a></h2><ul><li><strong>定位</strong>：阿里云旗舰预览模型，提供 <strong>≈256K</strong> 上下文，面向长文档处理与企业问答。</li><li><strong>优势</strong>： <ul><li><strong>快</strong>：非思考架构 + API 工程优化，响应延迟低。</li><li><strong>长上下文</strong>：上下文缓存可降低重复计算成本。</li><li><strong>商用能力</strong>：阿里云 Model Studio、OpenRouter 多渠道接入。</li></ul></li><li><strong>技术报告</strong>：暂无独立 Max-Preview 报告，可参考 <strong>Qwen3 总技术报告</strong>了解架构背景。</li></ul><hr><h2 id="kimi-k2-0905-开源·权重可得" tabindex="-1">Kimi K2-0905（开源·权重可得） <a class="header-anchor" href="#kimi-k2-0905-开源·权重可得" aria-label="Permalink to &quot;Kimi K2-0905（开源·权重可得）&quot;">​</a></h2><blockquote><p>面向「Agentic Intelligence」的超大规模 MoE 基座 + 强代理后训练体系；0905 版在 Agentic Coding 与上下文长度（256K）进一步增强，已开放 Base / Instruct 权重。</p></blockquote><h3 id="模型结构特点" tabindex="-1">模型结构特点 <a class="header-anchor" href="#模型结构特点" aria-label="Permalink to &quot;模型结构特点&quot;">​</a></h3><ul><li><strong>超稀疏 MoE 基座</strong>： <ul><li><strong>总参 ~1T，激活 ~32B，Top-8 路由</strong>；</li><li>以 <strong>MLA（Multi-head Latent Attention）</strong> 为注意力骨干，面向长上下文推理的 <strong>FLOPs/吞吐</strong> 做了结构侧优化（相较同类，将注意力头数下调以换取长序列推理效率）。</li></ul></li><li><strong>面向 Agent 的工程取向</strong>： <ul><li>以“工具使用 + 多步规划”为第一性能力目标，在架构/后训练全流程对 <strong>Agentic</strong> 场景做增强；</li><li>开源 <strong>Base/Instruct</strong> 权重便于私有化与二次研究。</li></ul></li><li><strong>上下文窗口</strong>： <ul><li>技术报告覆盖至 <strong>128K</strong> 的扩展策略；</li><li><strong>K2-0905 Instruct</strong> 将服务侧上下文进一步 <strong>扩至 256K</strong>。</li></ul></li></ul><hr><h2 id="附录-训练与数据-实现细节" tabindex="-1">附录｜训练与数据（实现细节） <a class="header-anchor" href="#附录-训练与数据-实现细节" aria-label="Permalink to &quot;附录｜训练与数据（实现细节）&quot;">​</a></h2><h3 id="a-预训练稳定化与配方" tabindex="-1">A. 预训练稳定化与配方 <a class="header-anchor" href="#a-预训练稳定化与配方" aria-label="Permalink to &quot;A. 预训练稳定化与配方&quot;">​</a></h3><ul><li><strong>QK-Clip 机制</strong>：训练步后读取各头最大 attention logit (S_{\\max}^h)，当超阈值 <strong>τ=100</strong> 时，仅对 <strong>MLA 的非共享分量</strong>执行缩放（(q_C,k_C) 乘 (\\sqrt{\\gamma})，(q_R) 乘 (\\gamma)，共享 (k_R) 不动），<strong>不改变当步前后向</strong>；早期常激活，收敛后<strong>自停用</strong>。</li><li><strong>配方要点</strong>：总计 <strong>15.5T tokens</strong>；主程窗口 <strong>4k</strong>，尾段以 <strong>YaRN</strong> 激活 <strong>32k/128k</strong>；学习率与 batch 采用“预热-持平-余弦衰减”。</li></ul><h3 id="b-数据-提升-token-utility" tabindex="-1">B. 数据：提升 token-utility <a class="header-anchor" href="#b-数据-提升-token-utility" aria-label="Permalink to &quot;B. 数据：提升 token-utility&quot;">​</a></h3><ul><li><strong>知识/数学重写</strong>：以<strong>分块自回归重写</strong>替代多 epoch 重复，结合多风格/多视角提示，提升<strong>每 token 学习信号</strong>；多语互译与题型改写覆盖知识/数学等域。</li></ul><h3 id="c-后训练-sft-→-联合-rl" tabindex="-1">C. 后训练：SFT → 联合 RL <a class="header-anchor" href="#c-后训练-sft-→-联合-rl" aria-label="Permalink to &quot;C. 后训练：SFT → 联合 RL&quot;">​</a></h3><ul><li><strong>SFT</strong>：延续 <strong>Muon</strong> 做指令微调；多域高质数据（含模型与人审）过滤。</li><li><strong>Agentic 数据合成</strong>：真实/合成工具池 + 任务/代理/轨迹三级生成与判别过滤，规模化获得<strong>可验证工具使用轨迹</strong>。</li><li><strong>统一 RL</strong>： <ul><li><strong>RLVR</strong>：在可判定任务上以<strong>二值可验证奖励</strong>直接优化“做成事”。</li><li><strong>自评 Rubric 奖励</strong>：使用器对生成进行成对排序/打分（偏好、深度、事实性、安全等维），与 RLVR 形成闭环，抑制 reward-hacking。</li></ul></li></ul><h3 id="d-系统与长上下文" tabindex="-1">D. 系统与长上下文 <a class="header-anchor" href="#d-系统与长上下文" aria-label="Permalink to &quot;D. 系统与长上下文&quot;">​</a></h3><ul><li><strong>并行与内存</strong>：报告描述了 PP/EP/DP 组合与重算、FP8 激活存储、CPU-offload 等手段以控制显存峰值并重叠通信；为 <strong>128K</strong> 长上下文推理打基础。<strong>0905</strong> 在线服务侧将窗口拉升到 <strong>256K</strong>。</li></ul>',19)])])}const m=r(e,[["render",s]]);export{d as __pageData,m as default};
