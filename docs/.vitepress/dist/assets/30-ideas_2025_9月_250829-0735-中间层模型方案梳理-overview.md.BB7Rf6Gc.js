import{_ as e,c as t,o as a,ag as l}from"./chunks/framework.CQuhCYrb.js";const d=JSON.parse('{"title":"中间层模型方案梳理","description":"","frontmatter":{"title":"中间层模型方案梳理","created":"2025-09-07 17:02","updated":"2025-09-07T00:00:00.000Z","origin":"week-35","type":"idea","status":"draft","tags":[],"links":[]},"headers":[],"relativePath":"30-ideas/2025/9月/250829-0735-中间层模型方案梳理-overview.md","filePath":"30-ideas/2025/9月/250829-0735-中间层模型方案梳理-overview.md"}'),o={name:"30-ideas/2025/9月/250829-0735-中间层模型方案梳理-overview.md"};function n(r,i,s,_,u,h){return a(),t("div",null,[...i[0]||(i[0]=[l('<h2 id="问题" tabindex="-1">问题 <a class="header-anchor" href="#问题" aria-label="Permalink to &quot;问题&quot;">​</a></h2><ul><li></li></ul><h2 id="原因-洞察" tabindex="-1">原因/洞察 <a class="header-anchor" href="#原因-洞察" aria-label="Permalink to &quot;原因/洞察&quot;">​</a></h2><ul><li></li></ul><h2 id="下一步行动" tabindex="-1">下一步行动 <a class="header-anchor" href="#下一步行动" aria-label="Permalink to &quot;下一步行动&quot;">​</a></h2><ul><li>[ ]</li><li>[ ]</li></ul><h2 id="raw-notes" tabindex="-1">Raw Notes <a class="header-anchor" href="#raw-notes" aria-label="Permalink to &quot;Raw Notes&quot;">​</a></h2><h1 id="中间层方案梳理-0828" tabindex="-1">中间层方案梳理 0828 <a class="header-anchor" href="#中间层方案梳理-0828" aria-label="Permalink to &quot;中间层方案梳理 0828&quot;">​</a></h1><h2 id="_1-让-metaquery-分化为-text-vision-vl-并在自注意里-各看各的" tabindex="-1">1) 让 metaquery 分化为 text / vision / vl，并在自注意里“各看各的” <a class="header-anchor" href="#_1-让-metaquery-分化为-text-vision-vl-并在自注意里-各看各的" aria-label="Permalink to &quot;1) 让 metaquery 分化为 text / vision / vl，并在自注意里“各看各的”&quot;">​</a></h2><p><strong>核心做法：</strong></p><ul><li>预置三簇可学习的 query 向量：q_text (Nt), q_vision (Nv), q_vl (Nvl)；</li><li>拼接序列顺序：[ text_tokens | vision_tokens | q_text | q_vision | q_vl ]；</li><li>构造块稀疏的 causal 自注意 mask： <ul><li>q_text 只看 {text_tokens, 过往 q_text}；</li><li>q_vision 只看 {vision_tokens, 过往 q_vision}；</li><li>q_vl 可看 {text_tokens, vision_tokens, 过往 q_vl}；</li><li>其它不该看的位置一律 -inf；</li><li>整体仍保持 causal（每个位置只看自己之前的 token）。</li></ul></li></ul><p>方案2：不用cross atten ，将vl query作为序列前段，输入到一个MoE里，连接到高斯空间；多模态MoE就是MoE llama的做法就是多个MLP + Router；</p><p>clip 只是为了让高斯分布具有图像的属性；</p><h2 id="_2-用-cross-attention-把-text-信息注入-vision-query-再仅用-vision-query-做-flow" tabindex="-1">2) 用 Cross-Attention 把 text 信息注入 vision-query，再仅用 vision-query 做 flow <a class="header-anchor" href="#_2-用-cross-attention-把-text-信息注入-vision-query-再仅用-vision-query-做-flow" aria-label="Permalink to &quot;2) 用 Cross-Attention 把 text 信息注入 vision-query，再仅用 vision-query 做 flow&quot;">​</a></h2><p><strong>核心做法：</strong></p><ul><li>追加一层（或多层）专门的 Text→Vision Cross-Attention： Q = h_qv，K=V = text_context（可用 h_qt 或全量 text_tokens）；</li><li>用 门控残差（gating residual）避免分布偏移过度；</li><li>（可选）KL 约束：在 cross 融合前后，对 h_qv 映射出 (μ, logσ²)，对两高斯做 KL，限制融合不发散。</li><li></li></ul><h2 id="_3-将-vision-query-映射到-vae-高斯潜空间-再做-flow-matching" tabindex="-1">3) 将 vision-query 映射到 VAE 高斯潜空间，再做 Flow-Matching <a class="header-anchor" href="#_3-将-vision-query-映射到-vae-高斯潜空间-再做-flow-matching" aria-label="Permalink to &quot;3) 将 vision-query 映射到 VAE 高斯潜空间，再做 Flow-Matching&quot;">​</a></h2><p>FrozenAutoencoderKL 有：</p><ul><li>encode(image) -&gt; posterior N(μ_img, σ_img^2)，可采样得到 z_img；</li><li>latent_channels=C，潜空间分辨率约 H=W=img_size/8（SD 风格）。</li></ul><p><strong>目标</strong>： 把 h_qv_fused (B, Nv, D) 投到 (B, C, H, W) 的高斯潜变量 z0 ~ N(μ0, σ0^2)，与图像潜变量 z1 做 Flow-Matching。最简单稳定的做法：</p><ul><li>先把 Nv 个 token 聚合到一个潜网格（learned latent grid，尺寸 H*W）；</li><li>再用 1x1 Conv 映射出 μ0/ logσ0²。</li></ul><p>t -&gt; i, i,t(cond) -&gt; i</p><ul><li>问题1：文本作为条件进行约束，就是要实现i,t(cond) -&gt; i;</li><li>问题2：3层线性层不行的话改为6层tansformer，用MoE的结构进行query 到 z_text的映射；</li><li></li></ul>',23)])])}const q=e(o,[["render",n]]);export{d as __pageData,q as default};
