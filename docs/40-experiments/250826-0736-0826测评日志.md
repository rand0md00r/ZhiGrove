---
title: 0826测评日志
created: 2025-09-07 17:00
updated: 2025-09-07
origin: week-35
type: experiment
status: draft
tags: []
links: []
---

## EXP CONFIG META（把下块注释贴进你的配置文件顶部）

# ======================================================================
# EXP CONFIG META (paste at top of your .yaml / .toml / .ini config file)
# ----------------------------------------------------------------------
# EXP_ID      : <exp_yyyymmdd_x>          # e.g., exp_20250903_A
# TITLE       : <short one-liner>         # e.g., 5L transencoder, metaquery=256(no-decouple), LR×5
# PURPOSE     : <what this config is testing/ablation>
# KEY_DIFFS   : <the 2–4 knobs that distinguish this config from baseline>
# DATASET     : <e.g., 24M t2i>
# HARDWARE    : <e.g., A100×64>
# BRANCH/COMMIT: <wyq_dev / abc1234>      # optional
# CORE PARAMS : lr=<...>, batch=<...>, res=<...>, seed=<...>
# TAGS        : [<ablation>, <lrx5>, <5L>, <no-decouple>]   # optional
# NOTES       : <any caveat, e.g., warmup↑, grad_clip needed, etc.>
# ======================================================================


## 目标
- 

## 设置（与基线的差异）
- 数据/分辨率/学习率/权重 等关键改动（≤4 条）

## 指标与记录（训练/推理）
- <iters> / <metric: value>
- <样例路径或截图>

## 结论
- <保留/否决/待复验>

## 下一步
- 

## Raw Notes

下面是今天的开发日志（精简版）：

# 2025-08-26 开发日志

* ## 评测接口适配

  * **问题**：`generate` 被评测脚本调用时出现 `generator` 未定义；cond/uncond 拼批逻辑与返回张量需对齐脚本。
  * **处理**：统一本地变量 `gen` 并显式传入采样；仅输出前半 **cond** 批的结果；保持输出为 `[-1,1]`、`[B,3,H,W]`。

* ## 与训练一致的 AE/解码链路

  * **问题**：推理最初调用了 `pixels_to_latents/latents_to_pixels`，但训练用的是 `self.autoencoder` 的 **encode\_moments → FM → sample → decode**。
  * **处理**：推理改为：`encode_moments` 确定目标分布/形状 → ODE 积分得到 latent → **`self.autoencoder.sample(latent)`** → **`self.autoencoder.decode(z)`** 得到图像，完全对齐训练路径。

* ## 初态映射（\_zproj\_to\_latent）

  * **问题**：无条件引入随机初始化的线性投影会造成**分布漂移**。
  * **处理**：**优先 reshape**（`z_text → [B,C,Hh,Ww]`）；仅当维度不匹配时才临时线性映射兜底，并提示风险。

* ## `log_snr` 维度对齐

  * **问题**：`fm_transformers` 断言 `log_snr.dim()==1`，之前传入了 `[B,1]`/`[B,1,1,1]`。
  * **处理**：推理时显式构造一维 `log_snr`：`torch.full((B,), 4-8*t_k, ...)`；CFG 拼批时用 `torch.full((2*B,), ...)`。

* ## 时间采样（与训练分布一致且数值稳定）

  * **问题**：逐步随机 `t` 不利于 ODE 连续积分与复现。
  * **处理**：采用 **logit-normal 分位点时间网格**：用 Normal 的 `icdf` 得到 `z_edges` → `t_edges=sigmoid(z_edges)`，取中点 `t_mid`，步长 `dt = diff(t_edges)`；每步 `log_snr = 4 - 8 * t_mid[k]`（一维向量）。

* ## 推理时使用 `null_indicator`（CFG）

  * **问题**：如何在推理侧做 CFG 且保持维度正确。
  * **处理**：**速度域 CFG**：拼接 `x_cat=[x_cond; x_cond]`，构造一维 `log_snr`（长度 `2B`），`null_indicator[B:]=True` 表示 uncond；得到 `v_cond/v_uncond` 后按 `v=(1+w)v_cond - w v_uncond` 合成，再更新 **`x`**。避免与“初态混合”CFG叠加。

* ## 解码变量明确

  * **结论**：**解码的就是积分后的 `x`（条件批 latent）**；不要把 `x_cat` 或 `v_all` 送解码器。

* ## 形状确认

  * **观测**：`(1,3,256,256) → (1,32,8,8)`，即 `latent_channels=32`、下采样因子 `32`；512 分辨率对应展平维度 `8192`。评测/训练尽量统一分辨率，避免频繁重建映射层。

**下一步建议**：小网格搜索 `cfg_scale∈{0,2,3,4.5,6}`；固定评测分辨率；为 `log_snr`/`null_indicator`/时间网格加断言单测，确保形状与数值一致。
