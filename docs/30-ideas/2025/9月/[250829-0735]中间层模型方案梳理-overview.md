---
title: 中间层模型方案梳理
created: 2025-09-07 17:02
updated: 2025-09-07
origin: week-35
type: idea
status: draft
tags: []
links: []
---

## 问题
- 

## 原因/洞察
- 

## 下一步行动
- [ ] 
- [ ] 


## Raw Notes

# 中间层方案梳理 0828

## 1) 让 metaquery 分化为 text / vision / vl，并在自注意里“各看各的”
**核心做法：**
- 预置三簇可学习的 query 向量：q_text (Nt), q_vision (Nv), q_vl (Nvl)；
- 拼接序列顺序：[ text_tokens | vision_tokens | q_text | q_vision | q_vl ]；
- 构造块稀疏的 causal 自注意 mask：
  - q_text 只看 {text_tokens, 过往 q_text}；
  - q_vision 只看 {vision_tokens, 过往 q_vision}；
  - q_vl 可看 {text_tokens, vision_tokens, 过往 q_vl}；
  - 其它不该看的位置一律 -inf；
  - 整体仍保持 causal（每个位置只看自己之前的 token）。

方案2：不用cross atten ，将vl query作为序列前段，输入到一个MoE里，连接到高斯空间；多模态MoE就是MoE llama的做法就是多个MLP + Router；

clip 只是为了让高斯分布具有图像的属性；

## 2) 用 Cross-Attention 把 text 信息注入 vision-query，再仅用 vision-query 做 flow
**核心做法：**
- 追加一层（或多层）专门的 Text→Vision Cross-Attention：
  Q = h_qv，K=V = text_context（可用 h_qt 或全量 text_tokens）；
- 用 门控残差（gating residual）避免分布偏移过度；
- （可选）KL 约束：在 cross 融合前后，对 h_qv 映射出 (μ, logσ²)，对两高斯做 KL，限制融合不发散。
- 

## 3) 将 vision-query 映射到 VAE 高斯潜空间，再做 Flow-Matching
FrozenAutoencoderKL 有：
- encode(image) -> posterior N(μ_img, σ_img^2)，可采样得到 z_img；
- latent_channels=C，潜空间分辨率约 H=W=img_size/8（SD 风格）。

**目标**： 把 h_qv_fused (B, Nv, D) 投到 (B, C, H, W) 的高斯潜变量 z0 ~ N(μ0, σ0^2)，与图像潜变量 z1 做 Flow-Matching。最简单稳定的做法：
- 先把 Nv 个 token 聚合到一个潜网格（learned latent grid，尺寸 H*W）；
- 再用 1x1 Conv 映射出 μ0/ logσ0²。

t -> i, i,t(cond) -> i
- 问题1：文本作为条件进行约束，就是要实现i,t(cond) -> i;
- 问题2：3层线性层不行的话改为6层tansformer，用MoE的结构进行query 到 z_text的映射；
- 

